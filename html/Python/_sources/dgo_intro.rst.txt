purpose
-------

The ``dgo`` package uses a deterministic partition-and-bound trust-region
method to find an approximation to the global minimizer of a
differentiable objective function $f(x)$ of n variables $x$,
subject to simple bounds $x^l <= x <= x^u$ on the variables.
Here, any of the components of the vectors of bounds $x^l$ and $x^u$
may be infinite. The method offers the choice of direct and
iterative solution of the key trust-region subproblems, and
is suitable for large problems. First derivatives are required,
and if second derivatives can be calculated, they will be exploited -
if the product of second derivatives with a vector may be found but
not the derivatives themselves, that may also be exploited.

Although there are theoretical guarantees, these may require a large
number of evaluations as the dimension and nonconvexity increase.
The alternative package ``bgo`` may sometimes be preferred.

See Section 4 of $GALAHAD/doc/dgo.pdf for additional details.

method
------

Starting with the initial box $x^l \leq x \leq x^u$, a sequence of 
boxes is generated by considering the current set, and partitioning
a promising candidate into three equally-sized sub-boxes by splitting 
along one of the box dimensions. Each partition requires only a pair of 
new function and derivative evaluations, and these values, together with 
estimates of Lipschitz constants, makes it possible to remove other boxes 
from further consideration as soon as they cannot contain a global minimizer. 
Efficient control of the dictionary of vertices of the sub-boxes
is handled using a suitable hashing procedure provided by 
``HASH``; each sub-box is indexed by the concatenated 
coordinates of a pair of opposite vertices. At various
stages, local minimization in a promising sub-box, using 
``TRB``, may be used to improve the best-known upper bound 
on the global minimizer.
If $n=1$, the specialised univariate global minimization package 
``UGO`` is called directly.

We reiterate that although there are theoretical guarantees, 
these may require a large number of evaluations as the dimension 
and nonconvexity increase.
Thus the method should best be viewed as a heuristic to try to find
a reasonable approximation of the global minimum.

references
----------

The global minimization method employed is an extension of that due to

  Ya. D. Sergeyev and D. E. Kasov,
  ``A deterministic global optimization using smooth diagonal 
  auxiliary functions'',
  *Communications in Nonlinear Science and Numerical Simulation*,
  **21(1-3)** (2015) 99-111.

but adapted to use 2nd derivatives, while in the special case when $n=1$,
a simplification based on the ideas in

  D. Lera and Ya. D. Sergeyev (2013),
  ``Acceleration of univariate global optimization algorithms working with
  Lipschitz functions and Lipschitz first derivatives''
  *SIAM J. Optimization* **23(1)** (2013) 508â€“529.

is used instead. The generic bound-constrained trust-region method used 
for local minimization is described in detail in

  A. R. Conn, N. I. M. Gould and Ph. L. Toint,
  Trust-region methods.
  SIAM/MPS Series on Optimization (2000).
