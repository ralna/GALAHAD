
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>NLS &#8212; GALAHAD Python Interface 1.0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="_static/styles/bootstrap.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=796348d33e8b1d947c94" rel="stylesheet">
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/css/custom.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94">
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]]}})</script>
    <script>window.MathJax = {"tex": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]]}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'nls';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Linear Programming" href="lp.html" />
    <link rel="prev" title="BLLS" href="blls.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="docsearch:language" content="en">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>

  
  <input type="checkbox" class="sidebar-toggle" name="__primary" id="__primary">
  <label class="overlay overlay-primary" for="__primary"></label>

  
  <input type="checkbox" class="sidebar-toggle" name="__secondary" id="__secondary">
  <label class="overlay overlay-secondary" for="__secondary"></label>

  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
      
<form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
  </div>

  
  <nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
      <span class="fa-solid fa-bars"></span>
  </label>
  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="index.html">

  
  
  
  
  
  
  

  
    <img src="_static/galahad.small.png" class="logo__image only-light" alt="Logo image">
    <img src="_static/galahad.small.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  
  <div class="col-lg-9 navbar-header-items">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="uco.html">
                        Unconstrained Optimization
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="bco.html">
                        Bound-constrained Optimization
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="ls.html">
                        Least-Squares
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="lp.html">
                        Linear Programming
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="qp.html">
                        Quadratic Programming
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="reg.html">
                        Regularization subproblems
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="sys.html">
                        Linear Systems
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="go.html">
                        Global Optimization
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="aux.html">
                        Auxiliary Procedures
                      </a>
                    </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
    </div>

    <div id="navbar-end">
      
        <div class="navbar-end-item navbar-persistent--container">
          
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
        </div>
      
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>


  
  
    <div class="navbar-persistent--mobile">
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
    </div>
  

  
  <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
  </label>
  

</div>
  </nav>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        
  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="uco.html">
                        Unconstrained Optimization
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="bco.html">
                        Bound-constrained Optimization
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="ls.html">
                        Least-Squares
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="lp.html">
                        Linear Programming
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="qp.html">
                        Quadratic Programming
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="reg.html">
                        Regularization subproblems
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="sys.html">
                        Linear Systems
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="go.html">
                        Global Optimization
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="aux.html">
                        Auxiliary Procedures
                      </a>
                    </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
      </div>
    

    
    
    <div class="sidebar-header-items__end">
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
    
  </div>

  
  <div class="sidebar-start-items sidebar-primary__section">
    <div class="sidebar-start-items__item"><nav class="bd-links" id="bd-docs-nav" aria-label="Section navigation">
  <p class="bd-links__title" role="heading" aria-level="1">
    Section Navigation
  </p>
  <div class="bd-toc-item navbar-nav">
    <p aria-level="2" class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="blls.html">BLLS - bound-constrained linear least-squares using a preconditioned, projected-gradient method</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">NLS - unconstrained local nonlinear least-squares using a regularization method</a></li>
</ul>

  </div>
</nav>
    </div>
  </div>
  

  
  <div class="sidebar-end-items sidebar-primary__section">
    <div class="sidebar-end-items__item">
    </div>
  </div>

  
  <div id="rtd-footer-container"></div>

      </div>
      <main id="main-content" class="bd-main">
        
        
        <div class="bd-content">
          <div class="bd-article-container">
            
            <div class="bd-header-article">
                
            </div>
            
            
            <article class="bd-article" role="main">
              
  <section id="module-galahad.nls">
<span id="nls"></span><h1>NLS<a class="headerlink" href="#module-galahad.nls" title="Permalink to this heading">#</a></h1>
<p>The <code class="docutils literal notranslate"><span class="pre">nls</span></code> package uses a regularization method to find a (local) unconstrained
minimizer of a differentiable weighted sum-of-squares objective function
<div class="math notranslate nohighlight">
\[f(x) :=
\frac{1}{2} \sum_{i=1}^m w_i c_i^2(x) \equiv \frac{1}{2} \|c(x)\|^2_W\]</div>

of many variables <span class="math notranslate nohighlight">\(x\)</span> involving positive weights <span class="math notranslate nohighlight">\(w_i\)</span>, <span class="math notranslate nohighlight">\(i=1,\ldots,m\)</span>.
The method offers the choice of direct and iterative solution of the key
regularization subproblems, and is most suitable for large problems.
First derivatives of the residual function <span class="math notranslate nohighlight">\(c(x)\)</span> are required, and if
second derivatives of the <span class="math notranslate nohighlight">\(c_i(x)\)</span> can be calculated, they may be exploited.</p>
<p>See Section 4 of $GALAHAD/doc/nls.pdf for additional details.</p>
<section id="terminology">
<h2>terminology<a class="headerlink" href="#terminology" title="Permalink to this heading">#</a></h2>
<p>The <strong>gradient</strong> <span class="math notranslate nohighlight">\(\nabla_x f(x)\)</span> of a function <span class="math notranslate nohighlight">\(f(x)\)</span> is the vector
whose <span class="math notranslate nohighlight">\(i\)</span>-th component is <span class="math notranslate nohighlight">\(\partial f(x)/\partial x_i\)</span>.
The <strong>Hessian</strong> <span class="math notranslate nohighlight">\(\nabla_{xx} f(x)\)</span> of <span class="math notranslate nohighlight">\(f(x)\)</span> is the symmetric matrix
whose <span class="math notranslate nohighlight">\(i,j\)</span>-th entry is <span class="math notranslate nohighlight">\(\partial^2 f(x)/\partial x_i \partial x_j\)</span>.
The Hessian is <strong>sparse</strong> if a significant and useful proportion of the
entries are universally zero.</p>
<p>The algorithm used by the package is iterative. From the current best estimate
of the minimizer <span class="math notranslate nohighlight">\(x_k\)</span>, a trial improved point <span class="math notranslate nohighlight">\(x_k + s_k\)</span> is sought.
The correction <span class="math notranslate nohighlight">\(s_k\)</span> is chosen to improve a model <span class="math notranslate nohighlight">\(m_k(s)\)</span> of
the objective function <span class="math notranslate nohighlight">\(f(x_k+s)\)</span> built around
<span class="math notranslate nohighlight">\(x_k\)</span>. The model is the sum of two basic components,
a suitable approximation <span class="math notranslate nohighlight">\(t_k(s)\)</span> of <span class="math notranslate nohighlight">\(f(x_k+s)\)</span>,
%another approximation of <span class="math notranslate nohighlight">\((\rho/r) \|x_k+s\|_r^r\)</span> (if <span class="math notranslate nohighlight">\(\rho &gt; 0\)</span>),
and a regularization term <span class="math notranslate nohighlight">\((\sigma_k/p) \|s\|_{S_k}^p\)</span>
involving a weight <span class="math notranslate nohighlight">\(\sigma_k\)</span>, power <span class="math notranslate nohighlight">\(p\)</span> and
a norm <span class="math notranslate nohighlight">\(\|s\|_{S_k} := \sqrt{s^T S_k s}\)</span> for a given positive
definite scaling matrix <span class="math notranslate nohighlight">\(S_k\)</span> that is included to prevent large
corrections. The weight  <span class="math notranslate nohighlight">\(\sigma_k\)</span> is adjusted as the algorithm
progresses to  ensure convergence.</p>
<p>The model <span class="math notranslate nohighlight">\(t_k(s)\)</span> is a truncated Taylor-series approximation, and this
relies on being able to compute or estimate derivatives of <span class="math notranslate nohighlight">\(c(x)\)</span>.
Various models are provided, and each has different derivative requirements.
We denote the <span class="math notranslate nohighlight">\(m\)</span> by <span class="math notranslate nohighlight">\(n\)</span> residual <strong>Jacobian</strong>
<span class="math notranslate nohighlight">\(J(x) \equiv \nabla_x c(x)\)</span> as the matrix  whose <span class="math notranslate nohighlight">\(i,j\)</span>-th component
<div class="math notranslate nohighlight">
\[J(x)_{i,j} := \partial c_i(x) / \partial x_j \;\;
\mbox{for $i=1,\ldots,m$ and $j=1,\ldots,n$.}\]</div>

For a given <span class="math notranslate nohighlight">\(m\)</span>-vector <span class="math notranslate nohighlight">\(y\)</span>, the
<strong>weighted-residual Hessian</strong> is the sum
<div class="math notranslate nohighlight">
\[H(x,y) := \sum_{\ell=1}^m y_{\ell} H_{\ell}(x), \;\; \mbox{where}\;\; H_{\ell}(x)_{i,j} := \partial^2 c_{\ell}(x) / \partial x_i \partial x_j \;\; \mbox{for $i,j=1,\ldots,n$}\]</div>

is the Hessian of <span class="math notranslate nohighlight">\(c_\ell(x)\)</span>.
Finally, for a given vector <span class="math notranslate nohighlight">\(v\)</span>, we define
the <strong>residual-Hessians-vector product</strong> matrix
<div class="math notranslate nohighlight">
\[P(x,v) := (H_1(x) v, \ldots, H_m(x) v).\]</div>

The models <span class="math notranslate nohighlight">\(t_k(s)\)</span> provided are,</p>
<ol class="arabic">
<li><p>the <strong>first-order Taylor</strong> approximation
<span class="math notranslate nohighlight">\(f(x_k) + g(x_k)^T s\)</span>, where <span class="math notranslate nohighlight">\(g(x) = J^T(x) W c(x)\)</span>,</p></li>
<li><p>a <strong>barely second-order</strong> approximation
<span class="math notranslate nohighlight">\(f(x_k) + g(x_k)^T s + \frac{1}{2} s^T W s\)</span>,</p></li>
<li><p>the <strong>Gauss-Newton</strong> approximation
<span class="math notranslate nohighlight">\(\frac{1}{2} \| c(x_k) + J(x_k) s\|^2_W\)</span>,</p></li>
<li><p>the <strong>Newton (second-order Taylor)</strong> approximation</p>
<p><span class="math notranslate nohighlight">\(f(x_k) + g(x_k)^T s + \frac{1}{2} s^T [ J^T(x_k) W J(x_k) + H(x_k,W c(x_k))] s\)</span>, and</p>
</li>
<li><p>the <strong>tensor Gauss-Newton</strong> approximation
<span class="math notranslate nohighlight">\(\frac{1}{2} \| c(x_k) + J(x_k) s + \frac{1}{2} s^T \cdot P(x_k,s) \|^2_W\)</span>,
where the <span class="math notranslate nohighlight">\(i\)</span>-th component of <span class="math notranslate nohighlight">\(s^T \cdot P(x_k,s)\)</span> is
shorthand for the scalar <span class="math notranslate nohighlight">\(s^T H_i(x_k) s\)</span>,
where <span class="math notranslate nohighlight">\(W\)</span> is the diagonal matrix of weights
<span class="math notranslate nohighlight">\(w_i\)</span>, <span class="math notranslate nohighlight">\(i = 1, \ldots m\)</span>0.</p></li>
</ol>
</section>
<section id="method">
<h2>method<a class="headerlink" href="#method" title="Permalink to this heading">#</a></h2>
<p>An adaptive regularization method is used.
In this, an improvement to a current
estimate of the required minimizer, <span class="math notranslate nohighlight">\(x_k\)</span> is sought by computing a
step <span class="math notranslate nohighlight">\(s_k\)</span>. The step is chosen to approximately minimize a model <span class="math notranslate nohighlight">\(t_k(s)\)</span>
of <span class="math notranslate nohighlight">\(f_{\rho,r}(x_k+s)\)</span>
that includes a weighted regularization term
<span class="math notranslate nohighlight">\(\frac{\sigma_k}{p} \|s\|_{S_k}^p\)</span>
for some specified positive weight <span class="math notranslate nohighlight">\(\sigma_k\)</span>. The quality of the
resulting step <span class="math notranslate nohighlight">\(s_k\)</span> is assessed by computing the “ratio”
<span class="math notranslate nohighlight">\((f(x_k) - f(x_k + s_k))/(t_k(0) - t_k(s_k))\)</span>.
The step is deemed to have succeeded if the ratio exceeds a given <span class="math notranslate nohighlight">\(\eta_s &gt; 0\)</span>,
and in this case <span class="math notranslate nohighlight">\(x_{k+1} = x_k + s_k\)</span>. Otherwise
<span class="math notranslate nohighlight">\(x_{k+1} = x_k\)</span>, and the weight is increased by powers of a given
increase factor up to a given limit. If the ratio is larger than
<span class="math notranslate nohighlight">\(\eta_v \geq \eta_d\)</span>, the weight will be decreased by powers of a given
decrease factor again up to a given limit. The method will terminate
as soon as <span class="math notranslate nohighlight">\(f(x_k)\)</span> or
<span class="math notranslate nohighlight">\(\|\nabla_x f(x_k)\|\)</span> is smaller than a specified value.</p>
<p>A choice of linear, quadratic or quartic models <span class="math notranslate nohighlight">\(t_k(s)\)</span> is available
(see the previous section), and normally a two-norm regularization will
be used, but this may change if preconditioning is employed.</p>
<p>If linear or quadratic models are employed, an appropriate,
approximate model minimizer is found using either a direct approach
involving factorization of a shift of the model Hessian <span class="math notranslate nohighlight">\(B_k\)</span> or an
iterative (conjugate-gradient/Lanczos) approach based on approximations
to the required solution from a so-called Krlov subspace. The direct
approach is based on the knowledge that the required solution
satisfies the linear system of equations <span class="math notranslate nohighlight">\((B_k + \lambda_k I) s_k
= - \nabla_x f(x_k)\)</span> involving a scalar Lagrange multiplier <span class="math notranslate nohighlight">\(\lambda_k\)</span>.
This multiplier is found by uni-variate root finding, using a safeguarded
Newton-like process, by <code class="docutils literal notranslate"><span class="pre">RQS</span></code>. The iterative approach
uses <code class="docutils literal notranslate"><span class="pre">GLRT</span></code>, and is best accelerated by preconditioning with
good approximations to the Hessian of the model using <code class="docutils literal notranslate"><span class="pre">PSLS</span></code>. The
iterative approach has the advantage that only Hessian matrix-vector products
are required, and thus the Hessian <span class="math notranslate nohighlight">\(B_k\)</span> is not required explicitly.
However when factorizations of the Hessian are possible, the direct approach
is often more efficient.</p>
<p>When a quartic model is used, the model is itself of least-squares form,
and the package calls itself recursively to approximately minimize its
model. The quartic model often gives a better approximation, but at the
cost of more involved derivative requirements.</p>
</section>
<section id="references">
<h2>references<a class="headerlink" href="#references" title="Permalink to this heading">#</a></h2>
<p>The generic adaptive cubic regularization method is described in detail in</p>
<blockquote>
<div><p>C. Cartis,  N. I. M. Gould and Ph. L. Toint,
<a href="#id1"><span class="problematic" id="id2">``</span></a>Adaptive cubic regularisation methods for unconstrained optimization.
Part I: motivation, convergence and numerical results’’
<em>Mathematical Programming</em> <strong>127(2)</strong> (2011) 245–295,</p>
</div></blockquote>
<p>and uses <a href="#id3"><span class="problematic" id="id4">``</span></a>tricks’’ as suggested in</p>
<blockquote>
<div><p>N. I. M. Gould, M. Porcelli and Ph. L. Toint,
<a href="#id5"><span class="problematic" id="id6">``</span></a>Updating the regularization parameter in the adaptive cubic regularization
algorithm’’.
<em>Computational Optimization and Applications</em>
<strong>53(1)</strong> (2012) 1–22.</p>
</div></blockquote>
<p>The specific methods employed here are discussed in</p>
<blockquote>
<div><p>N. I. M. Gould, J. A. Scott and T. Rees,
<a href="#id7"><span class="problematic" id="id8">``</span></a>Convergence and evaluation-complexity analysis of a regularized
tensor-Newton method for solving nonlinear least-squares problems’’.
<em>Computational Optimization and Applications</em>
<strong>73(1)</strong> (2019) 1–35.</p>
</div></blockquote>
</section>
<section id="matrix-storage">
<h2>matrix storage<a class="headerlink" href="#matrix-storage" title="Permalink to this heading">#</a></h2>
<p>The <strong>unsymmetric</strong> <span class="math notranslate nohighlight">\(m\)</span> by <span class="math notranslate nohighlight">\(n\)</span> Jacobian matrix <span class="math notranslate nohighlight">\(J = J(x)\)</span> and the
residual-Hessians-vector product matrix <span class="math notranslate nohighlight">\(P(x,v)\)</span> may be presented
and stored in a variety of convenient input formats. Let
<span class="math notranslate nohighlight">\(A\)</span> be <span class="math notranslate nohighlight">\(J\)</span> or <span class="math notranslate nohighlight">\(P\)</span> as appropriate.</p>
<p><em>Dense</em> storage format:
The matrix <span class="math notranslate nohighlight">\(A\)</span> is stored as a compact  dense matrix by rows, that is,
the values of the entries of each row in turn are
stored in order within an appropriate real one-dimensional array.
In this case, component <span class="math notranslate nohighlight">\(n \ast i + j\)</span>  of the storage array A_val
will hold the value <span class="math notranslate nohighlight">\(A_{ij}\)</span> for <span class="math notranslate nohighlight">\(0 \leq i \leq m-1\)</span>, <span class="math notranslate nohighlight">\(0 \leq j \leq n-1\)</span>.</p>
<p><em>Dense by columns</em> storage format:
The matrix <span class="math notranslate nohighlight">\(A\)</span> is stored as a compact  dense matrix by columns, that is,
the values of the entries of each column in turn are
stored in order within an appropriate real one-dimensional array.
In this case, component <span class="math notranslate nohighlight">\(m \ast j + i\)</span>  of the storage array A_val
will hold the value <span class="math notranslate nohighlight">\(A_{ij}\)</span> for <span class="math notranslate nohighlight">\(0 \leq i \leq m-1\)</span>, <span class="math notranslate nohighlight">\(0 \leq j \leq n-1\)</span>.</p>
<p><em>Sparse co-ordinate</em> storage format:
Only the nonzero entries of the matrices are stored.
For the <span class="math notranslate nohighlight">\(l\)</span>-th entry, <span class="math notranslate nohighlight">\(0 \leq l \leq ne-1\)</span>, of <span class="math notranslate nohighlight">\(A\)</span>,
its row index i, column index j and value <span class="math notranslate nohighlight">\(A_{ij}\)</span>,
<span class="math notranslate nohighlight">\(0 \leq i \leq m-1\)</span>,  <span class="math notranslate nohighlight">\(0 \leq j \leq n-1\)</span>,  are stored as
the <span class="math notranslate nohighlight">\(l\)</span>-th components of the integer arrays A_row and
A_col and real array A_val, respectively, while the number of nonzeros
is recorded as A_ne = <span class="math notranslate nohighlight">\(ne\)</span>.</p>
<p><em>Sparse row-wise storage</em> format:
Again only the nonzero entries are stored, but this time
they are ordered so that those in row i appear directly before those
in row i+1. For the i-th row of <span class="math notranslate nohighlight">\(A\)</span> the i-th component of the
integer array A_ptr holds the position of the first entry in this row,
while A_ptr(m) holds the total number of entries.
The column indices j, <span class="math notranslate nohighlight">\(0 \leq j \leq n-1\)</span>, and values
<span class="math notranslate nohighlight">\(A_{ij}\)</span> of the  nonzero entries in the i-th row are stored in components
l = A_ptr(i), <span class="math notranslate nohighlight">\(\ldots\)</span>, A_ptr(i+1)-1,  <span class="math notranslate nohighlight">\(0 \leq i \leq m-1\)</span>,
of the integer array A_col, and real array A_val, respectively.
For sparse matrices, this scheme almost always requires less storage than
its predecessor.</p>
<p><em>Sparse column-wise</em> storage format:
Once again only the nonzero entries are stored, but this time
they are ordered so that those in column j appear directly before those
in column j+1. For the j-th column of <span class="math notranslate nohighlight">\(A\)</span> the j-th component of the
integer array A_ptr holds the position of the first entry in this column,
while A_ptr(n) holds the total number of entries.
The row indices i, <span class="math notranslate nohighlight">\(0 \leq i \leq m-1\)</span>, and values <span class="math notranslate nohighlight">\(A_{ij}\)</span>
of the  nonzero entries in the j-th columnsare stored in components
l = A_ptr(j), <span class="math notranslate nohighlight">\(\ldots\)</span>, A_ptr(j+1)-1, <span class="math notranslate nohighlight">\(0 \leq j \leq n-1\)</span>,
of the integer array A_row, and real array A_val, respectively.
As before, for sparse matrices, this scheme almost always requires less
storage than the co-ordinate format.</p>
<p>The <strong>symmetric</strong> <span class="math notranslate nohighlight">\(n\)</span> by <span class="math notranslate nohighlight">\(n\)</span> matrix <span class="math notranslate nohighlight">\(H = H(x,y)\)</span> may
be presented and stored in a variety of formats. But crucially symmetry
is exploited by only storing values from the lower triangular part
(i.e, those entries that lie on or below the leading diagonal).</p>
<p><em>Dense</em> storage format:
The matrix <span class="math notranslate nohighlight">\(H\)</span> is stored as a compact  dense matrix by rows, that
is, the values of the entries of each row in turn are stored in order
within an appropriate real one-dimensional array. Since <span class="math notranslate nohighlight">\(H\)</span> is
symmetric, only the lower triangular part (that is the part
<span class="math notranslate nohighlight">\(H_{ij}\)</span> for <span class="math notranslate nohighlight">\(0 \leq j \leq i \leq n-1\)</span>) need be held.
In this case the lower triangle should be stored by rows, that is
component <span class="math notranslate nohighlight">\(i * i / 2 + j\)</span>  of the storage array H_val
will hold the value <span class="math notranslate nohighlight">\(H_{ij}\)</span> (and, by symmetry, <span class="math notranslate nohighlight">\(H_{ji}\)</span>)
for <span class="math notranslate nohighlight">\(0 \leq j \leq i \leq n-1\)</span>.</p>
<p><em>Sparse co-ordinate</em> storage format:
Only the nonzero entries of the matrices are stored.
For the <span class="math notranslate nohighlight">\(l\)</span>-th entry, <span class="math notranslate nohighlight">\(0 \leq l \leq ne-1\)</span>, of <span class="math notranslate nohighlight">\(H\)</span>,
its row index i, column index j and value <span class="math notranslate nohighlight">\(H_{ij}\)</span>,
<span class="math notranslate nohighlight">\(0 \leq j \leq i \leq n-1\)</span>,  are stored as the <span class="math notranslate nohighlight">\(l\)</span>-th
components of the integer arrays H_row and H_col and real array H_val,
respectively, while the number of nonzeros is recorded as
H_ne = <span class="math notranslate nohighlight">\(ne\)</span>. Note that only the entries in the lower triangle
should be stored.</p>
<p><em>Sparse row-wise</em> storage format:
Again only the nonzero entries are stored, but this time
they are ordered so that those in row i appear directly before those
in row i+1. For the i-th row of <span class="math notranslate nohighlight">\(H\)</span> the i-th component of the
integer array H_ptr holds the position of the first entry in this row,
while H_ptr(n) holds the total number of entries.
The column indices j, <span class="math notranslate nohighlight">\(0 \leq j \leq i\)</span>, and values
<span class="math notranslate nohighlight">\(H_{ij}\)</span> of the  entries in the i-th row are stored in components
l = H_ptr(i), …, H_ptr(i+1)-1 of the
integer array H_col, and real array H_val, respectively. Note that
as before only the entries in the lower triangle should be stored. For
sparse matrices, this scheme almost always requires less storage than
its predecessor.</p>
<p><em>Diagonal</em> storage format:
If <span class="math notranslate nohighlight">\(H\)</span> is diagonal (i.e., <span class="math notranslate nohighlight">\(H_{ij} = 0\)</span> for all
<span class="math notranslate nohighlight">\(0 \leq i \neq j \leq n-1\)</span>) only the diagonals entries
<span class="math notranslate nohighlight">\(H_{ii}\)</span>, <span class="math notranslate nohighlight">\(0 \leq i \leq n-1\)</span> need
be stored, and the first n components of the array H_val may be
used for the purpose.</p>
<p><em>Multiples of the identity</em> storage format:
If <span class="math notranslate nohighlight">\(H\)</span> is a multiple of the identity matrix, (i.e., <span class="math notranslate nohighlight">\(H = \alpha I\)</span>
where <span class="math notranslate nohighlight">\(I\)</span> is the n by n identity matrix and <span class="math notranslate nohighlight">\(\alpha\)</span> is a scalar),
it suffices to store <span class="math notranslate nohighlight">\(\alpha\)</span> as the first component of H_val.</p>
<p>The <em>identity matrix</em> format:
If <span class="math notranslate nohighlight">\(H\)</span> is the identity matrix, no values need be stored.</p>
<p>The <em>zero matrix</em> format:
The same is true if <span class="math notranslate nohighlight">\(H\)</span>7 is the zero matrix.</p>
</section>
<section id="functions">
<h2>functions<a class="headerlink" href="#functions" title="Permalink to this heading">#</a></h2>
<blockquote>
<div><dl class="py function">
<dt class="sig sig-object py" id="galahad.nls.nls.initialize">
<span class="sig-prename descclassname"><span class="pre">nls.</span></span><span class="sig-name descname"><span class="pre">initialize</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#galahad.nls.nls.initialize" title="Permalink to this definition">#</a></dt>
<dd><p>Set default option values and initialize private data</p>
<p><strong>Returns:</strong></p>
<dl>
<dt>options<span class="classifier">dict</span></dt><dd><dl>
<dt>dictionary containing default control options:</dt><dd><dl>
<dt>error<span class="classifier">int</span></dt><dd><p>error and warning diagnostics occur on stream error.</p>
</dd>
<dt>out<span class="classifier">int</span></dt><dd><p>general output occurs on stream out.</p>
</dd>
<dt>print_level<span class="classifier">int</span></dt><dd><p>the level of output required. Possible values are</p>
<ul>
<li><p><strong>&lt;= 0</strong></p>
<p>gives no output.</p>
</li>
<li><p><strong>1</strong></p>
<p>gives a one-line summary for every iteration.</p>
</li>
<li><p><strong>2</strong></p>
<p>gives a summary of the inner iteration for each iteration.</p>
</li>
<li><p><strong>&gt;=3</strong></p>
<p>gives increasingly verbose (debugging) output.</p>
</li>
</ul>
</dd>
<dt>start_print<span class="classifier">int</span></dt><dd><p>any printing will start on this iteration.</p>
</dd>
<dt>stop_print<span class="classifier">int</span></dt><dd><p>any printing will stop on this iteration.</p>
</dd>
<dt>print_gap<span class="classifier">int</span></dt><dd><p>the number of iterations between printing.</p>
</dd>
<dt>maxit<span class="classifier">int</span></dt><dd><p>the maximum number of iterations performed.</p>
</dd>
<dt>alive_unit<span class="classifier">int</span></dt><dd><p>removal of the file alive_file from unit alive_unit
terminates execution.</p>
</dd>
<dt>alive_file<span class="classifier">str</span></dt><dd><p>see alive_unit.</p>
</dd>
<dt>jacobian_available<span class="classifier">int</span></dt><dd><p>is the Jacobian matrix of first derivatives available
(<span class="math notranslate nohighlight">\(\geq\)</span> 2), is access only via matrix-vector products
(=1) or is it not available (<span class="math notranslate nohighlight">\(\leq\)</span> 0) ?.</p>
</dd>
<dt>hessian_available<span class="classifier">int</span></dt><dd><p>is the Hessian matrix of second derivatives available
(<span class="math notranslate nohighlight">\(\geq\)</span> 2), is access only via matrix-vector products
(=1) or is it not available (<span class="math notranslate nohighlight">\(\leq\)</span> 0) ?.</p>
</dd>
<dt>model<span class="classifier">int</span></dt><dd><p>the model used.  Possible values are</p>
<ul>
<li><p><strong>0</strong></p>
<p>dynamic (<em>not yet implemented</em>)</p>
</li>
<li><p><strong>1</strong></p>
<p>first-order (no Hessian)</p>
</li>
<li><p><strong>2</strong></p>
<p>barely second-order (identity Hessian)</p>
</li>
<li><p><strong>3</strong></p>
<p>Gauss-Newton (<span class="math notranslate nohighlight">\(J^T J\)</span> Hessian)</p>
</li>
<li><p><strong>4</strong></p>
<p>second-order (exact Hessian)</p>
</li>
<li><p><strong>5</strong></p>
<p>Gauss-Newton to Newton transition</p>
</li>
<li><p><strong>6</strong></p>
<p>tensor Gauss-Newton treated as a least-squares model</p>
</li>
<li><p><strong>7</strong></p>
<p>tensor Gauss-Newton treated as a general model</p>
</li>
<li><p><strong>8</strong></p>
<p>tensor Gauss-Newton transition from a least-squares
to a general mode.</p>
</li>
</ul>
</dd>
<dt>norm<span class="classifier">int</span></dt><dd><p>the regularization norm used. The norm is defined via
<span class="math notranslate nohighlight">\(\|v\|^2 = v^T S v\)</span>, and will define the preconditioner
used for iterative methods. Possible values for <span class="math notranslate nohighlight">\(S\)</span> are</p>
<ul>
<li><p><strong>-3</strong></p>
<p>user’s own regularization norm</p>
</li>
<li><p><strong>-2</strong></p>
<p><span class="math notranslate nohighlight">\(S\)</span> = limited-memory BFGS matrix (with
<code class="docutils literal notranslate"><span class="pre">PSLS_options.lbfgs_vectors</span></code> history) (<em>not yet implemented</em>)</p>
</li>
<li><p><strong>-1</strong></p>
<p>identity (= Euclidan two-norm)</p>
</li>
<li><p><strong>0</strong></p>
<p>automatic (<em>not yet implemented</em>)</p>
</li>
<li><p><strong>1</strong></p>
<p>diagonal, <span class="math notranslate nohighlight">\(S\)</span> = diag( max( <span class="math notranslate nohighlight">\(J^TJ\)</span> Hessian,
<code class="docutils literal notranslate"><span class="pre">PSLS_options.min_diagonal</span></code> ) )</p>
</li>
<li><p><strong>2</strong></p>
<p>diagonal, <span class="math notranslate nohighlight">\(S\)</span> = diag( max( Hessian,
<code class="docutils literal notranslate"><span class="pre">PSLS_options.min_diagonal</span></code> ) )</p>
</li>
<li><p><strong>3</strong></p>
<p>banded, <span class="math notranslate nohighlight">\(S\)</span> = band( Hessian ) with semi-bandwidth
<code class="docutils literal notranslate"><span class="pre">PSLS_options.semi_bandwidth</span></code></p>
</li>
<li><p><strong>4</strong></p>
<p>re-ordered band, <span class="math notranslate nohighlight">\(S\)</span> = band(order(A)) with semi-bandwidth</p>
<p><code class="docutils literal notranslate"><span class="pre">PSLS_options.semi_bandwidth</span></code></p>
</li>
<li><p><strong>5</strong></p>
<p>full factorization, <span class="math notranslate nohighlight">\(S\)</span> = Hessian, Schnabel-Eskow
modification</p>
</li>
<li><p><strong>6</strong></p>
<p>full factorization, <span class="math notranslate nohighlight">\(S\)</span> = Hessian, GMPS modification
(<em>not yet implemented</em>)</p>
</li>
<li><p><strong>7</strong></p>
<p>incomplete factorization of Hessian, Lin-More’</p>
</li>
<li><p><strong>8</strong></p>
<p>incomplete factorization of Hessian, HSL_MI28</p>
</li>
<li><p><strong>9</strong></p>
<p>incomplete factorization of Hessian, Munskgaard
(<em>not yet implemented</em>)</p>
</li>
<li><p><strong>10</strong></p>
<p>expanding band of Hessian (<em>not yet implemented</em>).</p>
</li>
</ul>
</dd>
<dt>non_monotone<span class="classifier">int</span></dt><dd><p>non-monotone &lt;= 0 monotone strategy used, anything else
non-monotone strategy with this history length used.</p>
</dd>
<dt>weight_update_strategy<span class="classifier">int</span></dt><dd><p>define the weight-update strategy: 1 (basic), 2 (reset to
zero when very successful), 3 (imitate TR), 4 (increase
lower bound), 5 (GPT).</p>
</dd>
<dt>stop_c_absolute<span class="classifier">float</span></dt><dd><p>overall convergence tolerances. The iteration will
terminate when <span class="math notranslate nohighlight">\(||c(x)||_2 \leq \max(\)</span>
<code class="docutils literal notranslate"><span class="pre">stop_c_absolute,</span></code> <code class="docutils literal notranslate"><span class="pre">stop_c_relative</span></code> *
<span class="math notranslate nohighlight">\(\|c(x_{\mbox{initial}})\|_2\)</span> or when the norm of the
gradient, <span class="math notranslate nohighlight">\(g = J^T(x) c(x) / \|c(x)\|_2\)</span>, of ||c(x)||_2
satisfies <span class="math notranslate nohighlight">\(\|g\|_2 \leq \max(\)</span> <code class="docutils literal notranslate"><span class="pre">stop_g_absolute,</span></code>
<code class="docutils literal notranslate"><span class="pre">stop_g_relative</span></code> * <span class="math notranslate nohighlight">\(\|g_{\mbox{initial}}\|_2\)</span>, or if
the step is less than <code class="docutils literal notranslate"><span class="pre">stop_s</span></code>.</p>
</dd>
<dt>stop_c_relative<span class="classifier">float</span></dt><dd><p>see stop_c_absolute.</p>
</dd>
<dt>stop_g_absolute<span class="classifier">float</span></dt><dd><p>see stop_c_absolute.</p>
</dd>
<dt>stop_g_relative<span class="classifier">float</span></dt><dd><p>see stop_c_absolute.</p>
</dd>
<dt>stop_s<span class="classifier">float</span></dt><dd><p>see stop_c_absolute.</p>
</dd>
<dt>power<span class="classifier">float</span></dt><dd><p>the regularization power (&lt;2 means chosen according to the
model).</p>
</dd>
<dt>initial_weight<span class="classifier">float</span></dt><dd><p>initial value for the regularization weight (-ve means
<span class="math notranslate nohighlight">\(1/\|g_0\|)\)</span>).</p>
</dd>
<dt>minimum_weight<span class="classifier">float</span></dt><dd><p>minimum permitted regularization weight.</p>
</dd>
<dt>initial_inner_weight<span class="classifier">float</span></dt><dd><p>initial value for the inner regularization weight for
tensor GN (-ve means 0).</p>
</dd>
<dt>eta_successful<span class="classifier">float</span></dt><dd><p>potential iterate will only be accepted if the actual
decrease f - f(x_new) is larger than <code class="docutils literal notranslate"><span class="pre">eta_successful</span></code>
times that predicted by a quadratic model of the decrease.
The regularization weight will be decreaed if this
relative decrease is greater than <code class="docutils literal notranslate"><span class="pre">eta_very_successful</span></code>
but smaller than <code class="docutils literal notranslate"><span class="pre">eta_too_successful</span></code>.</p>
</dd>
<dt>eta_very_successful<span class="classifier">float</span></dt><dd><p>see eta_successful.</p>
</dd>
<dt>eta_too_successful<span class="classifier">float</span></dt><dd><p>see eta_successful.</p>
</dd>
<dt>weight_decrease_min<span class="classifier">float</span></dt><dd><p>on very successful iterations, the regularization weight
will be reduced by the factor <code class="docutils literal notranslate"><span class="pre">weight_decrease</span></code> but no
more than <code class="docutils literal notranslate"><span class="pre">weight_decrease_min</span></code> while if the iteration
is unsucceful, the weight will be increased by a factor
<code class="docutils literal notranslate"><span class="pre">weight_increase</span></code> but no more than
<code class="docutils literal notranslate"><span class="pre">weight_increase_max</span></code> (these are delta_1, delta_2,
delta3 and delta_max in Gould, Porcelli and Toint, 2011).</p>
</dd>
<dt>weight_decrease<span class="classifier">float</span></dt><dd><p>see weight_decrease_min</p>
</dd>
<dt>weight_increase<span class="classifier">float</span></dt><dd><p>see weight_decrease_min</p>
</dd>
<dt>weight_increase_max<span class="classifier">float</span></dt><dd><p>see weight_decrease_min</p>
</dd>
<dt>reduce_gap<span class="classifier">float</span></dt><dd><p>expert parameters as suggested in Gould, Porcelli and
Toint, “Updating the regularization parameter in the
adaptive cubic regularization algorithm” RAL-TR-2011-007,
Rutherford Appleton Laboratory, England (2011),
<a class="reference external" href="http://epubs.stfc.ac.uk/bitstream/6181/RAL-TR-2011-007.pdf">http://epubs.stfc.ac.uk/bitstream/6181/RAL-TR-2011-007.pdf</a>
(these are denoted beta, epsilon_chi and alpha_max in the
paper).</p>
</dd>
<dt>tiny_gap<span class="classifier">float</span></dt><dd><p>see reduce_gap.</p>
</dd>
<dt>large_root<span class="classifier">float</span></dt><dd><p>see reduce_gap.</p>
</dd>
<dt>switch_to_newton<span class="classifier">float</span></dt><dd><p>if the Gauss-Newto to Newton model is specified, switch to
Newton as soon as the norm of the gradient g is smaller
than switch_to_newton.</p>
</dd>
<dt>cpu_time_limit<span class="classifier">float</span></dt><dd><p>the maximum CPU time allowed (-ve means infinite).</p>
</dd>
<dt>clock_time_limit<span class="classifier">float</span></dt><dd><p>the maximum elapsed clock time allowed (-ve means
infinite).</p>
</dd>
<dt>subproblem_direct<span class="classifier">bool</span></dt><dd><p>use a direct (factorization) or (preconditioned) iterative
method to find the search direction.</p>
</dd>
<dt>renormalize_weight<span class="classifier">bool</span></dt><dd><p>should the weight be renormalized to account for a change
in scaling?.</p>
</dd>
<dt>magic_step<span class="classifier">bool</span></dt><dd><p>allow the user to perform a “magic” step to improve the
objective.</p>
</dd>
<dt>print_obj<span class="classifier">bool</span></dt><dd><p>print values of the objective/gradient rather than ||c||
and its gradient.</p>
</dd>
<dt>space_critical<span class="classifier">bool</span></dt><dd><p>if <code class="docutils literal notranslate"><span class="pre">space_critical</span></code> is True, every effort will be made to
use as little space as possible. This may result in longer
computation time.</p>
</dd>
<dt>deallocate_error_fatal<span class="classifier">bool</span></dt><dd><p>if <code class="docutils literal notranslate"><span class="pre">deallocate_error_fatal</span></code> is True, any array/pointer
deallocation error will terminate execution. Otherwise,
computation will continue.</p>
</dd>
<dt>prefix<span class="classifier">str</span></dt><dd><p>all output lines will be prefixed by the string contained
in quotes within <code class="docutils literal notranslate"><span class="pre">prefix</span></code>, e.g. ‘word’ (note the qutoes)
will result in the prefix word.</p>
</dd>
<dt>rqs_options<span class="classifier">dict</span></dt><dd><p>default control options for RQS (see <code class="docutils literal notranslate"><span class="pre">rqs.initialize</span></code>).</p>
</dd>
<dt>glrt_options<span class="classifier">dict</span></dt><dd><p>default control options for GLRT (see <code class="docutils literal notranslate"><span class="pre">glrt.initialize</span></code>).</p>
</dd>
<dt>psls_options<span class="classifier">dict</span></dt><dd><p>default control options for PSLS (see <code class="docutils literal notranslate"><span class="pre">psls.initialize</span></code>).</p>
</dd>
<dt>bsc_options<span class="classifier">dict</span></dt><dd><p>default control options for BSC (see <code class="docutils literal notranslate"><span class="pre">bsc.initialize</span></code>).</p>
</dd>
<dt>roots_options<span class="classifier">dict</span></dt><dd><p>default control options for ROOTS (see <code class="docutils literal notranslate"><span class="pre">roots.initialize</span></code>).</p>
</dd>
<dt>subproblem_options<span class="classifier">dict</span></dt><dd><dl>
<dt>default control options for the step-finding subproblem:</dt><dd><dl>
<dt>error<span class="classifier">int</span></dt><dd><p>error and warning diagnostics occur on stream error.</p>
</dd>
<dt>out<span class="classifier">int</span></dt><dd><p>general output occurs on stream out.</p>
</dd>
<dt>print_level<span class="classifier">int</span></dt><dd><p>the level of output required. Possible values are:</p>
<ul>
<li><p><strong>&lt;= 0</strong></p>
<p>gives no output.</p>
</li>
<li><p><strong>1</strong></p>
<p>gives a one-line summary for every iteration.</p>
</li>
<li><p><strong>2</strong></p>
<p>gives a summary of the inner iteration for each iteration.</p>
</li>
<li><p><strong>&gt;=3</strong></p>
<p>gives increasingly verbose (debugging) output.</p>
</li>
</ul>
</dd>
<dt>start_print<span class="classifier">int</span></dt><dd><p>any printing will start on this iteration.</p>
</dd>
<dt>stop_print<span class="classifier">int</span></dt><dd><p>any printing will stop on this iteration.</p>
</dd>
<dt>print_gap<span class="classifier">int</span></dt><dd><p>the number of iterations between printing.</p>
</dd>
<dt>maxit<span class="classifier">int</span></dt><dd><p>the maximum number of iterations performed.</p>
</dd>
<dt>alive_unit<span class="classifier">int</span></dt><dd><p>removal of the file alive_file from unit alive_unit
terminates execution.</p>
</dd>
<dt>alive_file<span class="classifier">str</span></dt><dd><p>see alive_unit.</p>
</dd>
<dt>jacobian_available<span class="classifier">int</span></dt><dd><p>is the Jacobian matrix of first derivatives available
(<span class="math notranslate nohighlight">\(\geq\)</span> 2), is access only via matrix-vector products
(=1) or is it not available (<span class="math notranslate nohighlight">\(\leq\)</span> 0) ?.</p>
</dd>
<dt>hessian_available<span class="classifier">int</span></dt><dd><p>is the Hessian matrix of second derivatives available
(<span class="math notranslate nohighlight">\(\geq\)</span> 2), is access only via matrix-vector products
(=1) or is it not available (<span class="math notranslate nohighlight">\(\leq\)</span> 0) ?.</p>
</dd>
<dt>model<span class="classifier">int</span></dt><dd><p>the model used.  Possible values are</p>
<ul>
<li><p><strong>0</strong></p>
<p>dynamic (<em>not yet implemented</em>)</p>
</li>
<li><p><strong>1</strong></p>
<p>first-order (no Hessian)</p>
</li>
<li><p><strong>2</strong></p>
<p>barely second-order (identity Hessian)</p>
</li>
<li><p><strong>3</strong></p>
<p>Gauss-Newton (<span class="math notranslate nohighlight">\(J^T J\)</span> Hessian)</p>
</li>
<li><p><strong>4</strong></p>
<p>second-order (exact Hessian)</p>
</li>
<li><p><strong>5</strong></p>
<p>Gauss-Newton to Newton transition</p>
</li>
<li><p><strong>6</strong></p>
<p>tensor Gauss-Newton treated as a least-squares model</p>
</li>
<li><p><strong>7</strong></p>
<p>tensor Gauss-Newton treated as a general model</p>
</li>
<li><p><strong>8</strong></p>
<p>tensor Gauss-Newton transition from a least-squares
to a general mode.</p>
</li>
</ul>
</dd>
<dt>norm<span class="classifier">int</span></dt><dd><p>the regularization norm used. The norm is defined via
<span class="math notranslate nohighlight">\(\|v\|^2 = v^T S v\)</span>, and will define the preconditioner
used for iterative methods. Possible values for <span class="math notranslate nohighlight">\(S\)</span> are</p>
<ul class="simple">
<li><p><strong>-3</strong></p></li>
</ul>
<p>user’s own regularization norm</p>
<ul class="simple">
<li><p><strong>-2</strong></p></li>
</ul>
<p><span class="math notranslate nohighlight">\(S\)</span> = limited-memory BFGS matrix (with</p>
<p><code class="docutils literal notranslate"><span class="pre">PSLS_options.lbfgs_vectors</span></code> history) (<em>not yet implemented</em>)</p>
<ul class="simple">
<li><p><strong>-1</strong></p></li>
</ul>
<p>identity (= Euclidan two-norm)</p>
<ul class="simple">
<li><p><strong>0</strong></p></li>
</ul>
<p>automatic (<em>not yet implemented</em>)</p>
<ul class="simple">
<li><p><strong>1</strong></p></li>
</ul>
<p>diagonal, <span class="math notranslate nohighlight">\(S\)</span> = diag( max( <span class="math notranslate nohighlight">\(J^TJ\)</span> Hessian,
<code class="docutils literal notranslate"><span class="pre">PSLS_options.min_diagonal</span></code> ) )</p>
<ul>
<li><p><strong>2</strong></p>
<p>diagonal, <span class="math notranslate nohighlight">\(S\)</span> = diag( max( Hessian,
<code class="docutils literal notranslate"><span class="pre">PSLS_options.min_diagonal</span></code> ) )</p>
</li>
<li><p><strong>3</strong></p>
<p>banded, <span class="math notranslate nohighlight">\(S\)</span> = band( Hessian ) with semi-bandwidth
<code class="docutils literal notranslate"><span class="pre">PSLS_options.semi_bandwidth</span></code></p>
</li>
<li><p><strong>4</strong></p>
<p>re-ordered band, P=band(order(A)) with semi-bandwidth
<code class="docutils literal notranslate"><span class="pre">PSLS_options.semi_bandwidth</span></code></p>
</li>
<li><p><strong>5</strong></p>
<p>full factorization, <span class="math notranslate nohighlight">\(S\)</span> = Hessian, Schnabel-Eskow
modification</p>
</li>
<li><p><strong>6</strong></p>
<p>full factorization, <span class="math notranslate nohighlight">\(S\)</span> = Hessian, GMPS modification
(<em>not yet implemented</em>)</p>
</li>
<li><p><strong>7</strong></p>
<p>incomplete factorization of Hessian, Lin-More’</p>
</li>
<li><p><strong>8</strong></p>
<p>incomplete factorization of Hessian, HSL_MI28</p>
</li>
<li><p><strong>9</strong></p>
<p>incomplete factorization of Hessian, Munskgaard
(<em>not yet implemented</em>)</p>
</li>
<li><p><strong>10</strong></p>
<p>expanding band of Hessian (<em>not yet implemented</em>).</p>
</li>
</ul>
</dd>
<dt>non_monotone<span class="classifier">int</span></dt><dd><p>non-monotone &lt;= 0 monotone strategy used, anything else
non-monotone strategy with this history length used.</p>
</dd>
<dt>weight_update_strategy<span class="classifier">int</span></dt><dd><p>define the weight-update strategy: 1 (basic), 2 (reset to
zero when very successful), 3 (imitate TR), 4 (increase
lower bound), 5 (GPT).</p>
</dd>
<dt>stop_c_absolute<span class="classifier">float</span></dt><dd><p>overall convergence tolerances. The iteration will
terminate when <span class="math notranslate nohighlight">\(||c(x)||_2 \leq \max(\)</span>
<code class="docutils literal notranslate"><span class="pre">stop_c_absolute,</span></code> <code class="docutils literal notranslate"><span class="pre">stop_c_relative</span></code> *
<span class="math notranslate nohighlight">\(\|c(x_{\mbox{initial}})\|_2\)</span> or when the norm of the
gradient, <span class="math notranslate nohighlight">\(g = J^T(x) c(x) / \|c(x)\|_2\)</span>, of ||c(x)||_2
satisfies <span class="math notranslate nohighlight">\(\|g\|_2 \leq \max(\)</span> <code class="docutils literal notranslate"><span class="pre">stop_g_absolute,</span></code>
<code class="docutils literal notranslate"><span class="pre">stop_g_relative</span></code> * <span class="math notranslate nohighlight">\(\|g_{\mbox{initial}}\|_2\)</span>, or if
the step is less than <code class="docutils literal notranslate"><span class="pre">stop_s</span></code>.</p>
</dd>
<dt>stop_c_relative<span class="classifier">float</span></dt><dd><p>see stop_c_absolute.</p>
</dd>
<dt>stop_g_absolute<span class="classifier">float</span></dt><dd><p>see stop_c_absolute.</p>
</dd>
<dt>stop_g_relative<span class="classifier">float</span></dt><dd><p>see stop_c_absolute.</p>
</dd>
<dt>stop_s<span class="classifier">float</span></dt><dd><p>see stop_c_absolute.</p>
</dd>
<dt>power<span class="classifier">float</span></dt><dd><p>the regularization power (&lt;2 means chosen according to the
model).</p>
</dd>
<dt>initial_weight<span class="classifier">float</span></dt><dd><p>initial value for the regularization weight (-ve means
<span class="math notranslate nohighlight">\(1/\|g_0\|)\)</span>).</p>
</dd>
<dt>minimum_weight<span class="classifier">float</span></dt><dd><p>minimum permitted regularization weight.</p>
</dd>
<dt>initial_inner_weight<span class="classifier">float</span></dt><dd><p>initial value for the inner regularization weight for
tensor GN (-ve means 0).</p>
</dd>
<dt>eta_successful<span class="classifier">float</span></dt><dd><p>potential iterate will only be accepted if the actual
decrease f - f(x_new) is larger than <code class="docutils literal notranslate"><span class="pre">eta_successful</span></code>
times that predicted by a quadratic model of the decrease.
The regularization weight will be decreaed if this
relative decrease is greater than <code class="docutils literal notranslate"><span class="pre">eta_very_successful</span></code>
but smaller than <code class="docutils literal notranslate"><span class="pre">eta_too_successful</span></code>.</p>
</dd>
<dt>eta_very_successful<span class="classifier">float</span></dt><dd><p>see eta_successful.</p>
</dd>
<dt>eta_too_successful<span class="classifier">float</span></dt><dd><p>see eta_successful.</p>
</dd>
<dt>weight_decrease_min<span class="classifier">float</span></dt><dd><p>on very successful iterations, the regularization weight
will be reduced by the factor <code class="docutils literal notranslate"><span class="pre">weight_decrease</span></code> but no
more than <code class="docutils literal notranslate"><span class="pre">weight_decrease_min</span></code> while if the iteration
is unsucceful, the weight will be increased by a factor
<code class="docutils literal notranslate"><span class="pre">weight_increase</span></code> but no more than
<code class="docutils literal notranslate"><span class="pre">weight_increase_max</span></code> (these are delta_1, delta_2,
delta3 and delta_max in Gould, Porcelli and Toint, 2011).</p>
</dd>
<dt>weight_decrease<span class="classifier">float</span></dt><dd><p>see weight_decrease_min</p>
</dd>
<dt>weight_increase<span class="classifier">float</span></dt><dd><p>see weight_decrease_min</p>
</dd>
<dt>weight_increase_max<span class="classifier">float</span></dt><dd><p>see weight_decrease_min</p>
</dd>
<dt>reduce_gap<span class="classifier">float</span></dt><dd><p>expert parameters as suggested in Gould, Porcelli and
Toint, “Updating the regularization parameter in the
adaptive cubic regularization algorithm” RAL-TR-2011-007,
Rutherford Appleton Laboratory, England (2011),
<a class="reference external" href="http://epubs.stfc.ac.uk/bitstream/6181/RAL-TR-2011-007.pdf">http://epubs.stfc.ac.uk/bitstream/6181/RAL-TR-2011-007.pdf</a>
(these are denoted beta, epsilon_chi and alpha_max in the
paper).</p>
</dd>
<dt>tiny_gap<span class="classifier">float</span></dt><dd><p>see reduce_gap.</p>
</dd>
<dt>large_root<span class="classifier">float</span></dt><dd><p>see reduce_gap.</p>
</dd>
<dt>switch_to_newton<span class="classifier">float</span></dt><dd><p>if the Gauss-Newto to Newton model is specified, switch to
Newton as soon as the norm of the gradient g is smaller
than switch_to_newton.</p>
</dd>
<dt>cpu_time_limit<span class="classifier">float</span></dt><dd><p>the maximum CPU time allowed (-ve means infinite).</p>
</dd>
<dt>clock_time_limit<span class="classifier">float</span></dt><dd><p>the maximum elapsed clock time allowed (-ve means
infinite).</p>
</dd>
<dt>subproblem_direct<span class="classifier">bool</span></dt><dd><p>use a direct (factorization) or (preconditioned) iterative
method to find the search direction.</p>
</dd>
<dt>renormalize_weight<span class="classifier">bool</span></dt><dd><p>should the weight be renormalized to account for a change
in scaling?.</p>
</dd>
<dt>magic_step<span class="classifier">bool</span></dt><dd><p>allow the user to perform a “magic” step to improve the
objective.</p>
</dd>
<dt>print_obj<span class="classifier">bool</span></dt><dd><p>print values of the objective/gradient rather than ||c||
and its gradient.</p>
</dd>
<dt>space_critical<span class="classifier">bool</span></dt><dd><p>if <code class="docutils literal notranslate"><span class="pre">space_critical</span></code> is True, every effort will be made to
use as little space as possible. This may result in longer
computation time.</p>
</dd>
<dt>deallocate_error_fatal<span class="classifier">bool</span></dt><dd><p>if <code class="docutils literal notranslate"><span class="pre">deallocate_error_fatal</span></code> is True, any array/pointer
deallocation error will terminate execution. Otherwise,
computation will continue.</p>
</dd>
<dt>prefix<span class="classifier">str</span></dt><dd><p>all output lines will be prefixed by
<code class="docutils literal notranslate"><span class="pre">prefix(2:LEN(TRIM(.prefix))-1)</span></code> where <code class="docutils literal notranslate"><span class="pre">prefix</span></code>
contains the required string enclosed in quotes, e.g.
“string” or ‘string’.</p>
</dd>
<dt>rqs_options<span class="classifier">dict</span></dt><dd><p>default control options for RQS (see <code class="docutils literal notranslate"><span class="pre">rqs.initialize</span></code>).</p>
</dd>
<dt>glrt_options<span class="classifier">dict</span></dt><dd><p>default control options for GLRT (see <code class="docutils literal notranslate"><span class="pre">glrt.initialize</span></code>).</p>
</dd>
<dt>psls_options<span class="classifier">dict</span></dt><dd><p>default control options for PSLS (see <code class="docutils literal notranslate"><span class="pre">psls.initialize</span></code>).</p>
</dd>
<dt>bsc_options<span class="classifier">dict</span></dt><dd><p>default control options for BSC (see <code class="docutils literal notranslate"><span class="pre">bsc.initialize</span></code>).</p>
</dd>
<dt>roots_options<span class="classifier">dict</span></dt><dd><p>default control options for ROOTS (see <code class="docutils literal notranslate"><span class="pre">roots.initialize</span></code>).</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="galahad.nls.nls.load">
<span class="sig-prename descclassname"><span class="pre">nls.</span></span><span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">m</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">J_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">J_ne</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">J_row</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">J_col</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">J_ptr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">H_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">H_ne</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">H_row</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">H_col</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">H_ptr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">P_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">P_ne</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">P_row</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">P_col</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">P_ptr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">w</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#galahad.nls.nls.load" title="Permalink to this definition">#</a></dt>
<dd><p>Import problem data into internal storage prior to solution.</p>
<p><strong>Parameters:</strong></p>
<dl class="simple">
<dt>n<span class="classifier">int</span></dt><dd><p>holds the number of variables.</p>
</dd>
<dt>m<span class="classifier">int</span></dt><dd><p>holds the number of residuals.</p>
</dd>
<dt>J_type<span class="classifier">string</span></dt><dd><p>specifies the unsymmetric storage scheme used for the Jacobian
<span class="math notranslate nohighlight">\(J = J(x)\)</span>.
It should be one of ‘coordinate’, ‘sparse_by_rows’ or ‘dense’;
lower or upper case variants are allowed.</p>
</dd>
<dt>J_ne<span class="classifier">int</span></dt><dd><p>holds the number of entries in <span class="math notranslate nohighlight">\(J\)</span> in the sparse co-ordinate storage
scheme. It need not be set for any of the other two schemes.</p>
</dd>
<dt>J_row<span class="classifier">ndarray(J_ne)</span></dt><dd><p>holds the row indices of <span class="math notranslate nohighlight">\(J\)</span>
in the sparse co-ordinate storage scheme. It need not be set for
any of the other two schemes, and in this case can be None.</p>
</dd>
<dt>J_col<span class="classifier">ndarray(J_ne)</span></dt><dd><p>holds the column indices of <span class="math notranslate nohighlight">\(J\)</span> in either the sparse co-ordinate,
or the sparse row-wise storage scheme. It need not be set when the
dense storage scheme is used, and in this case can be None.</p>
</dd>
<dt>J_ptr<span class="classifier">ndarray(m+1)</span></dt><dd><p>holds the starting position of each row of <span class="math notranslate nohighlight">\(J\)</span>, as well as the
total number of entries, in the sparse row-wise storage
scheme. It need not be set when the other schemes are used, and in
this case can be None.</p>
</dd>
<dt>H_type<span class="classifier">string, optional</span></dt><dd><p>specifies the symmetric storage scheme used for the Hessian
<span class="math notranslate nohighlight">\(H = H(x,y)\)</span>.
It should be one of ‘coordinate’, ‘sparse_by_rows’, ‘dense’ or
‘diagonal’; lower or upper case variants are allowed.
This and the following H_* arguments are only required if
a Newton approximation or tensor Gauss-Newton approximation
model is required (see control.model = 4,…,8).</p>
</dd>
<dt>H_ne<span class="classifier">int, optional</span></dt><dd><p>holds the number of entries in the  lower triangular part of
<span class="math notranslate nohighlight">\(H\)</span> in the sparse co-ordinate storage scheme. It need
not be set for any of the other three schemes.</p>
</dd>
<dt>H_row<span class="classifier">ndarray(H_ne), optional</span></dt><dd><p>holds the row indices of the lower triangular part of <span class="math notranslate nohighlight">\(H\)</span>
in the sparse co-ordinate storage scheme. It need not be set for
any of the other three schemes, and in this case can be None.</p>
</dd>
<dt>H_col<span class="classifier">ndarray(H_ne), optional</span></dt><dd><p>holds the column indices of the  lower triangular part of
<span class="math notranslate nohighlight">\(H\)</span> in either the sparse co-ordinate, or the sparse row-wise
storage scheme. It need not be set when the dense or diagonal
storage schemes are used, and in this case can be None.</p>
</dd>
<dt>H_ptr<span class="classifier">ndarray(n+1), optional</span></dt><dd><p>holds the starting position of each row of the lower triangular
part of <span class="math notranslate nohighlight">\(H\)</span>, as well as the total number of entries,
in the sparse row-wise storage scheme. It need not be set when the
other schemes are used, and in this case can be None.</p>
</dd>
<dt>P_type<span class="classifier">string, optional</span></dt><dd><p>specifies the unsymmetric storage scheme used for the residual
Hessian-product matrix <span class="math notranslate nohighlight">\(P = P(x,v)\)</span>.
It should be one of ‘sparse_by_columns’ or ‘dense_by_columns’
(with the intention that ‘coordinate’ will be added at some time);;
lower or upper case variants are allowed.
This and the following P_* arguments are only required if
a tensor Gauss-Newton approximation model is required
(see control.model = 6,7,8).</p>
</dd>
<dt>P_ne<span class="classifier">int, optional</span></dt><dd><p>holds the number of entries in <span class="math notranslate nohighlight">\(P\)</span> in the sparse co-ordinate storage
scheme. It need not be set for any of the other two schemes.</p>
</dd>
<dt>P_row<span class="classifier">ndarray(P_ne), optional</span></dt><dd><p>holds the row indices of <span class="math notranslate nohighlight">\(P\)</span>
in the sparse co-ordinate storage scheme. It need not be set for
any of the other two schemes, and in this case can be None.</p>
</dd>
<dt>P_col<span class="classifier">ndarray(P_ne), optional</span></dt><dd><p>holds the column indices of <span class="math notranslate nohighlight">\(P\)</span> in either the sparse co-ordinate,
or the sparse row-wise storage scheme. It need not be set when the
dense storage scheme is used, and in this case can be None.</p>
</dd>
<dt>P_ptr<span class="classifier">ndarray(n+1), optional</span></dt><dd><p>holds the starting position of each column of <span class="math notranslate nohighlight">\(P\)</span>, as well as the
total number of entries, in the sparse column-wise storage
scheme. It need not be set when the other schemes are used, and in
this case can be None.</p>
</dd>
<dt>w<span class="classifier">ndarray(n), optional</span></dt><dd><p>holds the vector of weights <span class="math notranslate nohighlight">\(w\)</span>. If w is not provided, weights of
one will be presumed.</p>
</dd>
<dt>options<span class="classifier">dict, optional</span></dt><dd><p>dictionary of control options (see <code class="docutils literal notranslate"><span class="pre">nls.initialize</span></code>).</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="galahad.nls.nls.solve">
<span class="sig-prename descclassname"><span class="pre">nls.</span></span><span class="sig-name descname"><span class="pre">solve</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">m</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_c</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">j_ne</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_j</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h_ne</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_h</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p_ne</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_hprod</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#galahad.nls.nls.solve" title="Permalink to this definition">#</a></dt>
<dd><p>Find an approximate local unconstrained minimizer of a given
least-squares function using a regularization method.</p>
<p><strong>Parameters:</strong></p>
<dl>
<dt>n<span class="classifier">int</span></dt><dd><p>holds the number of variables.</p>
</dd>
<dt>m<span class="classifier">int</span></dt><dd><p>holds the number of residuals.</p>
</dd>
<dt>x<span class="classifier">ndarray(n)</span></dt><dd><p>holds the values of optimization variables <span class="math notranslate nohighlight">\(x\)</span>.</p>
</dd>
<dt>eval_c<span class="classifier">callable</span></dt><dd><p>a user-defined function that must have the signature:</p>
<p><code class="docutils literal notranslate"><span class="pre">c</span> <span class="pre">=</span> <span class="pre">eval_c(x)</span></code></p>
<p>The components of the residual <span class="math notranslate nohighlight">\(c(x)\)</span> evaluated at <span class="math notranslate nohighlight">\(x\)</span> must be
assigned to <code class="docutils literal notranslate"><span class="pre">c</span></code>.</p>
</dd>
<dt>j_ne<span class="classifier">int</span></dt><dd><p>holds the number of entries in the Jacobian <span class="math notranslate nohighlight">\(J = J(x)\)</span>.</p>
</dd>
<dt>eval_j<span class="classifier">callable</span></dt><dd><p>a user-defined function that must have the signature:</p>
<p><code class="docutils literal notranslate"><span class="pre">j</span> <span class="pre">=</span> <span class="pre">eval_(x)</span></code></p>
<p>The components of the nonzeros in the Jacobian
<span class="math notranslate nohighlight">\(J(x)\)</span> of the objective function evaluated at
<span class="math notranslate nohighlight">\(x\)</span> must be assigned to <code class="docutils literal notranslate"><span class="pre">j</span></code> in the same order as specified
in the sparsity pattern in <code class="docutils literal notranslate"><span class="pre">nls.load</span></code>.</p>
</dd>
<dt>h_ne<span class="classifier">int, optional</span></dt><dd><p>holds the number of entries in the lower triangular part of
the Hessian <span class="math notranslate nohighlight">\(H = H(x,y\)</span>.
This and the following eval_h argument are only required if
a Newton approximation or tensor Gauss-Newton approximation
model is required (see control.model = 4,…,8).</p>
</dd>
<dt>eval_h<span class="classifier">callable, optional</span></dt><dd><p>a user-defined function that must have the signature:</p>
<p><code class="docutils literal notranslate"><span class="pre">h</span> <span class="pre">=</span> <span class="pre">eval_h(x,y)</span></code></p>
<p>The components of the nonzeros in the lower triangle of the Hessian
<span class="math notranslate nohighlight">\(H(x,y)\)</span> evaluated at <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> must be assigned to <code class="docutils literal notranslate"><span class="pre">h</span></code> in the
same order as specified in the sparsity pattern in <code class="docutils literal notranslate"><span class="pre">nls.load</span></code>.</p>
</dd>
<dt>p_ne<span class="classifier">int, optional</span></dt><dd><p>holds the number of entries in the residual
Hessian-product matrix <span class="math notranslate nohighlight">\(P = P(x,v)\)</span>.
This and the following eval_hprod argument are only required if
a Newton approximation or tensor Gauss-Newton approximation
model is required (see control.model = 6,7,8).</p>
</dd>
<dt>eval_hprod<span class="classifier">callable, optional</span></dt><dd><p>a user-defined function that must have the signature:</p>
<p><code class="docutils literal notranslate"><span class="pre">p</span> <span class="pre">=</span> <span class="pre">eval_hprod(x,v)</span></code></p>
<p>The components of the nonzeros in the Hessian producr matrix
<span class="math notranslate nohighlight">\(P(x,y)\)</span> evaluated at <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(v\)</span> must be assigned to <code class="docutils literal notranslate"><span class="pre">p</span></code> in the
same order as specified in the sparsity pattern in <code class="docutils literal notranslate"><span class="pre">nls.load</span></code>.</p>
</dd>
</dl>
<p><strong>Returns:</strong></p>
<dl class="simple">
<dt>x<span class="classifier">ndarray(n)</span></dt><dd><p>holds the value of the approximate minimizer <span class="math notranslate nohighlight">\(x\)</span> after
a successful call.</p>
</dd>
<dt>c<span class="classifier">ndarray(m)</span></dt><dd><p>holds the value of the residuals <span class="math notranslate nohighlight">\(c(x)\)</span>.</p>
</dd>
<dt>g<span class="classifier">ndarray(n)</span></dt><dd><p>holds the gradient <span class="math notranslate nohighlight">\(\nabla f(x)\)</span> of the objective function.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">[optional]</span> <span class="pre">nls.information()</span></span></dt>
<dd><p>Provide optional output information</p>
<p><strong>Returns:</strong></p>
<dl>
<dt>inform<span class="classifier">dict</span></dt><dd><dl>
<dt>dictionary containing output information:</dt><dd><dl>
<dt>status<span class="classifier">int</span></dt><dd><p>return status.  Possible values are:</p>
<ul>
<li><p><strong>0</strong></p>
<p>The run was succesful.</p>
</li>
<li><p><strong>-1</strong></p>
<p>An allocation error occurred. A message indicating the
offending array is written on unit control[‘error’], and
the returned allocation status and a string containing
the name of the offending array are held in
inform[‘alloc_status’] and inform[‘bad_alloc’] respectively.</p>
</li>
<li><p><strong>-2</strong></p>
<p>A deallocation error occurred.  A message indicating the
offending array is written on unit control[‘error’] and
the returned allocation status and a string containing
the name of the offending array are held in
inform[‘alloc_status’] and inform[‘bad_alloc’] respectively.</p>
</li>
<li><p><strong>-3</strong></p>
<p>The restriction n &gt; 0 or m &gt; 0 or requirement that type contains
its relevant string ‘dense’, ‘coordinate’, ‘sparse_by_rows’,
‘diagonal’ or ‘absent’ has been violated.</p>
</li>
<li><p><strong>-9</strong></p>
<p>The analysis phase of the factorization failed; the return
status from the factorization package is given by
inform[‘factor_status’].</p>
</li>
<li><p><strong>-10</strong></p>
<p>The factorization failed; the return status from the
factorization package is given by inform[‘factor_status’].</p>
</li>
<li><p><strong>-11</strong></p>
<p>The solution of a set of linear equations using factors
from the factorization package failed; the return status
from the factorization package is given by
inform[‘factor_status’].</p>
</li>
<li><p><strong>-15</strong></p>
<p>The preconditioner <span class="math notranslate nohighlight">\(S(x)\)</span> appears not to be positive definite.</p>
</li>
<li><p><strong>-16</strong></p>
<p>The problem is so ill-conditioned that further progress
is impossible.</p>
</li>
<li><p><strong>-18</strong></p>
<p>Too many iterations have been performed. This may happen if
control[‘maxit’] is too small, but may also be symptomatic
of a badly scaled problem.</p>
</li>
<li><p><strong>-19</strong></p>
<p>The CPU time limit has been reached. This may happen if
control[‘cpu_time_limit’] is too small, but may also be
symptomatic of a badly scaled problem.</p>
</li>
<li><p><strong>-82</strong></p>
<p>The user has forced termination of the solver by removing
the file named control[‘alive_file’] from unit
control[‘alive_unit’].</p>
</li>
</ul>
</dd>
<dt>alloc_status<span class="classifier">int</span></dt><dd><p>the status of the last attempted allocation/deallocation.</p>
</dd>
<dt>bad_alloc<span class="classifier">str</span></dt><dd><p>the name of the array for which an allocation/deallocation
error occurred.</p>
</dd>
<dt>bad_eval<span class="classifier">str</span></dt><dd><p>the name of the user-supplied evaluation routine for which
an error occurred.</p>
</dd>
<dt>iter<span class="classifier">int</span></dt><dd><p>the total number of iterations performed.</p>
</dd>
<dt>cg_iter<span class="classifier">int</span></dt><dd><p>the total number of CG iterations performed.</p>
</dd>
<dt>c_eval<span class="classifier">int</span></dt><dd><p>the total number of evaluations of the residual function
c(x).</p>
</dd>
<dt>j_eval<span class="classifier">int</span></dt><dd><p>the total number of evaluations of the Jacobian J(x) of
c(x).</p>
</dd>
<dt>h_eval<span class="classifier">int</span></dt><dd><p>the total number of evaluations of the scaled Hessian
H(x,y) of c(x).</p>
</dd>
<dt>factorization_max<span class="classifier">int</span></dt><dd><p>the maximum number of factorizations in a sub-problem
solve.</p>
</dd>
<dt>factorization_status<span class="classifier">int</span></dt><dd><p>the return status from the factorization.</p>
</dd>
<dt>max_entries_factors<span class="classifier">long</span></dt><dd><p>the maximum number of entries in the factors.</p>
</dd>
<dt>factorization_integer<span class="classifier">long</span></dt><dd><p>the total integer workspace required for the factorization.</p>
</dd>
<dt>factorization_real<span class="classifier">long</span></dt><dd><p>the total real workspace required for the factorization.</p>
</dd>
<dt>factorization_average<span class="classifier">float</span></dt><dd><p>the average number of factorizations per sub-problem solve.</p>
</dd>
<dt>obj<span class="classifier">float</span></dt><dd><p>the value of the objective function
<span class="math notranslate nohighlight">\(\frac{1}{2}\|c(x)\|^2_W\)</span> at the best estimate the
solution, x, determined by NLS_solve.</p>
</dd>
<dt>norm_c<span class="classifier">float</span></dt><dd><p>the norm of the residual <span class="math notranslate nohighlight">\(\|c(x)\|_W\)</span> at the best estimate
of the solution x, determined by NLS_solve.</p>
</dd>
<dt>norm_g<span class="classifier">float</span></dt><dd><p>the norm of the gradient of <span class="math notranslate nohighlight">\(\|c(x)\|_W\)</span> of the objective
function at the best estimate, x, of the solution
determined by NLS_solve.</p>
</dd>
<dt>weight<span class="classifier">float</span></dt><dd><p>the final regularization weight used.</p>
</dd>
<dt>time<span class="classifier">dict</span></dt><dd><dl class="simple">
<dt>dictionary containing timing information:</dt><dd><dl class="simple">
<dt>total<span class="classifier">float</span></dt><dd><p>the total CPU time spent in the package.</p>
</dd>
<dt>preprocess<span class="classifier">float</span></dt><dd><p>the CPU time spent preprocessing the problem.</p>
</dd>
<dt>analyse<span class="classifier">float</span></dt><dd><p>the CPU time spent analysing the required matrices prior
to factorization.</p>
</dd>
<dt>factorize<span class="classifier">float</span></dt><dd><p>the CPU time spent factorizing the required matrices.</p>
</dd>
<dt>solve<span class="classifier">float</span></dt><dd><p>the CPU time spent computing the search direction.</p>
</dd>
<dt>clock_total<span class="classifier">float</span></dt><dd><p>the total clock time spent in the package.</p>
</dd>
<dt>clock_preprocess<span class="classifier">float</span></dt><dd><p>the clock time spent preprocessing the problem.</p>
</dd>
<dt>clock_analyse<span class="classifier">float</span></dt><dd><p>the clock time spent analysing the required matrices prior
to factorization.</p>
</dd>
<dt>clock_factorize<span class="classifier">float</span></dt><dd><p>the clock time spent factorizing the required matrices.</p>
</dd>
<dt>clock_solve<span class="classifier">float</span></dt><dd><p>the clock time spent computing the search direction.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
<dt>subproblem_inform<span class="classifier">dict</span></dt><dd><dl>
<dt>inform parameters for subproblem:</dt><dd><dl>
<dt>status<span class="classifier">int</span></dt><dd><p>return status.  Possible values are:</p>
<ul>
<li><p><strong>0</strong></p>
<p>The run was succesful.</p>
</li>
<li><p><strong>-1</strong></p>
<p>An allocation error occurred. A message indicating the
offending array is written on unit control[‘error’], and
the returned allocation status and a string containing
the name of the offending array are held in
inform[‘alloc_status’] and inform[‘bad_alloc’] respectively.</p>
</li>
<li><p><strong>-2</strong></p>
<p>A deallocation error occurred.  A message indicating the
offending array is written on unit control[‘error’] and
the returned allocation status and a string containing
the name of the offending array are held in
inform[‘alloc_status’] and inform[‘bad_alloc’] respectively.</p>
</li>
<li><p><strong>-3</strong></p>
<p>The restriction n &gt; 0 or m &gt; 0 or requirement that type contains
its relevant string ‘dense’, ‘coordinate’, ‘sparse_by_rows’,
‘diagonal’ or ‘absent’ has been violated.</p>
</li>
<li><p><strong>-9</strong></p>
<p>The analysis phase of the factorization failed; the return
status from the factorization package is given by
inform[‘factor_status’].</p>
</li>
<li><p><strong>-10</strong></p>
<p>The factorization failed; the return status from the
factorization package is given by inform[‘factor_status’].</p>
</li>
<li><p><strong>-11</strong></p>
<p>The solution of a set of linear equations using factors
from the factorization package failed; the return status
from the factorization package is given by
inform[‘factor_status’].</p>
</li>
<li><p><strong>-15</strong></p>
<p>The preconditioner <span class="math notranslate nohighlight">\(S(x)\)</span> appears not to be positive definite.</p>
</li>
<li><p><strong>-16</strong></p>
<p>The problem is so ill-conditioned that further progress
is impossible.</p>
</li>
<li><p><strong>-18</strong></p>
<p>Too many iterations have been performed. This may happen if
control[‘maxit’] is too small, but may also be symptomatic
of a badly scaled problem.</p>
</li>
<li><p><strong>-19</strong></p>
<p>The CPU time limit has been reached. This may happen if
control[‘cpu_time_limit’] is too small, but may also be
symptomatic of a badly scaled problem.</p>
</li>
<li><p><strong>-82</strong></p>
<p>The user has forced termination of the solver by removing
the file named control[‘alive_file’] from unit
control[‘alive_unit’].</p>
</li>
</ul>
</dd>
<dt>alloc_status<span class="classifier">int</span></dt><dd><p>the status of the last attempted allocation/deallocation.</p>
</dd>
<dt>bad_alloc<span class="classifier">str</span></dt><dd><p>the name of the array for which an allocation/deallocation
error occurred.</p>
</dd>
<dt>bad_eval<span class="classifier">str</span></dt><dd><p>the name of the user-supplied evaluation routine for which
an error occurred.</p>
</dd>
<dt>iter<span class="classifier">int</span></dt><dd><p>the total number of iterations performed.</p>
</dd>
<dt>cg_iter<span class="classifier">int</span></dt><dd><p>the total number of CG iterations performed.</p>
</dd>
<dt>c_eval<span class="classifier">int</span></dt><dd><p>the total number of evaluations of the residual function
c(x).</p>
</dd>
<dt>j_eval<span class="classifier">int</span></dt><dd><p>the total number of evaluations of the Jacobian J(x) of
c(x).</p>
</dd>
<dt>h_eval<span class="classifier">int</span></dt><dd><p>the total number of evaluations of the scaled Hessian
H(x,y) of c(x).</p>
</dd>
<dt>factorization_max<span class="classifier">int</span></dt><dd><p>the maximum number of factorizations in a sub-problem
solve.</p>
</dd>
<dt>factorization_status<span class="classifier">int</span></dt><dd><p>the return status from the factorization.</p>
</dd>
<dt>max_entries_factors<span class="classifier">long</span></dt><dd><p>the maximum number of entries in the factors.</p>
</dd>
<dt>factorization_integer<span class="classifier">long</span></dt><dd><p>the total integer workspace required for the factorization.</p>
</dd>
<dt>factorization_real<span class="classifier">long</span></dt><dd><p>the total real workspace required for the factorization.</p>
</dd>
<dt>factorization_average<span class="classifier">float</span></dt><dd><p>the average number of factorizations per sub-problem solve.</p>
</dd>
<dt>obj<span class="classifier">float</span></dt><dd><p>the value of the objective function
<span class="math notranslate nohighlight">\(\frac{1}{2}\|c(x)\|^2_W\)</span> at the best estimate the
solution, x, determined by NLS_solve.</p>
</dd>
<dt>norm_c<span class="classifier">float</span></dt><dd><p>the norm of the residual <span class="math notranslate nohighlight">\(\|c(x)\|_W\)</span> at the best estimate
of the solution x, determined by NLS_solve.</p>
</dd>
<dt>norm_g<span class="classifier">float</span></dt><dd><p>the norm of the gradient of <span class="math notranslate nohighlight">\(\|c(x)\|_W\)</span> of the objective
function at the best estimate, x, of the solution
determined by NLS_solve.</p>
</dd>
<dt>weight<span class="classifier">float</span></dt><dd><p>the final regularization weight used.</p>
</dd>
<dt>time<span class="classifier">dict</span></dt><dd><dl class="simple">
<dt>dictionary containing timing information:</dt><dd><dl class="simple">
<dt>total<span class="classifier">float</span></dt><dd><p>the total CPU time spent in the package.</p>
</dd>
<dt>preprocess<span class="classifier">float</span></dt><dd><p>the CPU time spent preprocessing the problem.</p>
</dd>
<dt>analyse<span class="classifier">float</span></dt><dd><p>the CPU time spent analysing the required matrices prior
to factorization.</p>
</dd>
<dt>factorize<span class="classifier">float</span></dt><dd><p>the CPU time spent factorizing the required matrices.</p>
</dd>
<dt>solve<span class="classifier">float</span></dt><dd><p>the CPU time spent computing the search direction.</p>
</dd>
<dt>clock_total<span class="classifier">float</span></dt><dd><p>the total clock time spent in the package.</p>
</dd>
<dt>clock_preprocess<span class="classifier">float</span></dt><dd><p>the clock time spent preprocessing the problem.</p>
</dd>
<dt>clock_analyse<span class="classifier">float</span></dt><dd><p>the clock time spent analysing the required matrices prior
to factorization.</p>
</dd>
<dt>clock_factorize<span class="classifier">float</span></dt><dd><p>the clock time spent factorizing the required matrices.</p>
</dd>
<dt>clock_solve<span class="classifier">float</span></dt><dd><p>the clock time spent computing the search direction.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
<dt>rqs_inform<span class="classifier">dict</span></dt><dd><p>inform parameters for RQS (see <code class="docutils literal notranslate"><span class="pre">rqs.information</span></code>).</p>
</dd>
<dt>glrt_inform<span class="classifier">dict</span></dt><dd><p>inform parameters for GLTR (see <code class="docutils literal notranslate"><span class="pre">glrt.information</span></code>).</p>
</dd>
<dt>psls_inform<span class="classifier">dict</span></dt><dd><p>inform parameters for PSLS (see <code class="docutils literal notranslate"><span class="pre">psls.information</span></code>).</p>
</dd>
<dt>bsc_inform<span class="classifier">dict</span></dt><dd><p>inform parameters for BSC (see <code class="docutils literal notranslate"><span class="pre">bsc.information</span></code>).</p>
</dd>
<dt>roots_inform<span class="classifier">dict</span></dt><dd><p>inform parameters for ROOTS (see <code class="docutils literal notranslate"><span class="pre">roots.information</span></code>).</p>
</dd>
</dl>
</dd>
</dl>
</dd>
<dt>rqs_inform<span class="classifier">dict</span></dt><dd><p>inform parameters for RQS (see <code class="docutils literal notranslate"><span class="pre">rqs.information</span></code>).</p>
</dd>
<dt>glrt_inform<span class="classifier">dict</span></dt><dd><p>inform parameters for GLTR (see <code class="docutils literal notranslate"><span class="pre">glrt.information</span></code>).</p>
</dd>
<dt>psls_inform<span class="classifier">dict</span></dt><dd><p>inform parameters for PSLS (see <code class="docutils literal notranslate"><span class="pre">psls.information</span></code>).</p>
</dd>
<dt>bsc_inform<span class="classifier">dict</span></dt><dd><p>inform parameters for BSC (see <code class="docutils literal notranslate"><span class="pre">bsc.information</span></code>).</p>
</dd>
<dt>roots_inform<span class="classifier">dict</span></dt><dd><p>inform parameters for ROOTS (see <code class="docutils literal notranslate"><span class="pre">roots.information</span></code>).</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="galahad.nls.nls.terminate">
<span class="sig-prename descclassname"><span class="pre">nls.</span></span><span class="sig-name descname"><span class="pre">terminate</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#galahad.nls.nls.terminate" title="Permalink to this definition">#</a></dt>
<dd><p>Deallocate all internal private storage.</p>
</dd></dl>

</div></blockquote>
</section>
<section id="example-code">
<h2>example code<a class="headerlink" href="#example-code" title="Permalink to this heading">#</a></h2>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">galahad</span> <span class="kn">import</span> <span class="n">nls</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">floatmode</span><span class="o">=</span><span class="s1">&#39;fixed&#39;</span><span class="p">)</span>

<span class="c1"># allocate internal data and set default options</span>
<span class="n">options</span> <span class="o">=</span> <span class="n">nls</span><span class="o">.</span><span class="n">initialize</span><span class="p">()</span>

<span class="c1"># set some non-default options</span>
<span class="n">options</span><span class="p">[</span><span class="s1">&#39;print_level&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">options</span><span class="p">[</span><span class="s1">&#39;jacobian_available&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">options</span><span class="p">[</span><span class="s1">&#39;hessian_available&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">options</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">6</span>
<span class="c1">#print(&quot;options:&quot;, options)</span>

<span class="c1"># set parameters</span>
<span class="n">p</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">m</span> <span class="o">=</span> <span class="mi">3</span>

<span class="c1"># set Jacobian sparsity</span>
<span class="n">J_type</span> <span class="o">=</span> <span class="s1">&#39;coordinate&#39;</span>
<span class="n">J_ne</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">J_row</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="n">J_col</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">J_ptr</span> <span class="o">=</span> <span class="kc">None</span>

<span class="c1"># set Hessian sparsity</span>
<span class="n">H_type</span> <span class="o">=</span> <span class="s1">&#39;coordinate&#39;</span>
<span class="n">H_ne</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">H_row</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">H_col</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">H_ptr</span> <span class="o">=</span> <span class="kc">None</span>

<span class="c1"># set Hessian product sparsity</span>
<span class="n">P_type</span> <span class="o">=</span> <span class="s1">&#39;sparse_by_columns&#39;</span>
<span class="n">P_ne</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">P_row</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">P_col</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">P_ptr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>

<span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">])</span>

<span class="c1"># load data (and optionally non-default options)</span>
<span class="n">nls</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span>
         <span class="n">J_type</span><span class="p">,</span> <span class="n">J_ne</span><span class="p">,</span> <span class="n">J_row</span><span class="p">,</span> <span class="n">J_col</span><span class="p">,</span> <span class="n">J_ptr</span><span class="p">,</span>
         <span class="n">H_type</span><span class="p">,</span> <span class="n">H_ne</span><span class="p">,</span> <span class="n">H_row</span><span class="p">,</span> <span class="n">H_col</span><span class="p">,</span> <span class="n">H_ptr</span><span class="p">,</span>
         <span class="n">P_type</span><span class="p">,</span> <span class="n">P_ne</span><span class="p">,</span> <span class="n">P_row</span><span class="p">,</span> <span class="n">P_col</span><span class="p">,</span> <span class="n">P_ptr</span><span class="p">,</span>
         <span class="n">w</span><span class="p">,</span> <span class="n">options</span><span class="p">)</span>

<span class="c1"># define residual function and its derivatives</span>
<span class="k">def</span> <span class="nf">eval_c</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">p</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
<span class="k">def</span> <span class="nf">eval_j</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.0</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">eval_h</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.0</span> <span class="o">*</span> <span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">y</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
<span class="k">def</span> <span class="nf">eval_hprod</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">v</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.0</span> <span class="o">*</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>

<span class="c1"># set starting point</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">])</span>

<span class="c1"># find optimum</span>
<span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">g</span> <span class="o">=</span> <span class="n">nls</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">eval_c</span><span class="p">,</span> <span class="n">J_ne</span><span class="p">,</span> <span class="n">eval_j</span><span class="p">,</span> <span class="n">H_ne</span><span class="p">,</span> <span class="n">eval_h</span><span class="p">,</span>
                    <span class="n">P_ne</span><span class="p">,</span> <span class="n">eval_hprod</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x:&quot;</span><span class="p">,</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;c:&quot;</span><span class="p">,</span><span class="n">c</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;g:&quot;</span><span class="p">,</span><span class="n">g</span><span class="p">)</span>

<span class="c1"># get information</span>
<span class="n">inform</span> <span class="o">=</span> <span class="n">nls</span><span class="o">.</span><span class="n">information</span><span class="p">()</span>
<span class="c1">#print(inform)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;f:&quot;</span><span class="p">,</span><span class="n">inform</span><span class="p">[</span><span class="s1">&#39;obj&#39;</span><span class="p">])</span>

<span class="c1"># deallocate internal data</span>
<span class="n">nls</span><span class="o">.</span><span class="n">terminate</span><span class="p">()</span>
</pre></div>
</div>
<p>This example code is available in $GALAHAD/src/nls/Python/test_nls.py .</p>
</section>
</section>


            </article>
            
            
            
            <footer class="bd-footer-article">
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
  <a class='left-prev' id="prev-link" href="blls.html" title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
          <p class="prev-next-subtitle">previous</p>
          <p class="prev-next-title">BLLS</p>
      </div>
  </a>
  <a class='right-next' id="next-link" href="lp.html" title="next page">
  <div class="prev-next-info">
      <p class="prev-next-subtitle">next</p>
      <p class="prev-next-title">Linear Programming</p>
  </div>
  <i class="fa-solid fa-angle-right"></i>
  </a>
</div>
            </footer>
            
          </div>
          
          
          
            <div class="bd-sidebar-secondary bd-toc">
              
<div class="toc-item">
  
<div class="tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
</div>
<nav id="bd-toc-nav" class="page-toc">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#terminology">
   terminology
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#method">
   method
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   references
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#matrix-storage">
   matrix storage
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#functions">
   functions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#galahad.nls.nls.initialize">
     <code class="docutils literal notranslate">
      <span class="pre">
       nls.initialize()
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#galahad.nls.nls.load">
     <code class="docutils literal notranslate">
      <span class="pre">
       nls.load()
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#galahad.nls.nls.solve">
     <code class="docutils literal notranslate">
      <span class="pre">
       nls.solve()
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#galahad.nls.nls.terminate">
     <code class="docutils literal notranslate">
      <span class="pre">
       nls.terminate()
      </span>
     </code>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#example-code">
   example code
  </a>
 </li>
</ul>

</nav>
</div>

<div class="toc-item">
  
<div id="searchbox"></div>
</div>

<div class="toc-item">
  
</div>

<div class="toc-item">
  
<div class="tocsection sourcelink">
    <a href="_sources/nls.rst.txt">
        <i class="fa-solid fa-file-lines"></i> Show Source
    </a>
</div>

</div>

            </div>
          
          
        </div>
        <footer class="bd-footer-content">
          <div class="bd-footer-content__inner">
            
          </div>
        </footer>
        
      </main>
    </div>
  </div>

  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94"></script>

  <footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    
<p class="copyright">

    &copy; Copyright Gould/Orban/Toint, for GALAHAD productions, GALAHAD 4 C/Python interfaces copyright Fowkes/Gould.<br>

</p>

  </div>
  
  <div class="footer-item">
    <p class="theme-version">
    Built with the
    <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">
        PyData Sphinx Theme
    </a>
    0.12.0.
</p>
  </div>
  
  <div class="footer-item">
    
<p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.3.0.<br>
</p>

  </div>
  
</div>
  </footer>
  </body>
</html>