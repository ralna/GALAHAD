\documentclass{galahad}

% set the package name

\newcommand{\package}{lanb}
\newcommand{\packagename}{LANCELOT\_simple}
\newcommand{\fullpackagename}{LANC\-E\-LOT\-\_simple}
\newcommand{\solver}{{\tt \fullpackagename}}
\newcommand{\external}{{\tt EXTERNAL}}

% other local definitions

\newcommand{\calC}{{\cal C}}
\renewcommand{\Re}{\hbox{I\hskip -1.5pt R}}

\begin{document}

\galheader

%%%%%%%%%%%%%%%%%%%%%% SUMMARY %%%%%%%%%%%%%%%%%%%%%%

\galsummary

{\tt \packagename} is a Fortran module for minimizing an objective function,
where the minimization variables are required to satisfy a set of auxiliary,
possibly nonlinear, constraints.  Bounds on the variables and known values may
be specified.  The module povides access to a single subroutine, called {\tt
LANCELOT\_simple}, which in turn provides a very simple calling sequence for
the much more powerful LANCELOT B pcakage.  Its simplicity results from the
fact that \packagename\ completely ignores partial separability and sparsity
structure, limits the forms under which the problem can be presented to the
solver and only allows for a very restricted choice of algorithmic parameters.
It is therefore of interest mostly for small-dimensional problems for which
ease of interface matters more than numerical performance.

\galbasics

We consider the nonlinear minimization problem given by
\[
\min_{x \in \smallRe^n} f( x ),
\]
possibly subject to constraints of the one or more of the forms
\[
l \leq  \bmx \leq u,
\]
\[
c_e( \bmx )  = 0,
\]
\[
c_i( \bmx ) \leq 0,
\]
where $f: \Re^n \rightarrow \Re$, $c_e: \Re^n \rightarrow \Re^{m}$ and
$c_i: \Re^n \rightarrow \Re^{q}$ are twice-continuously differentiable
functions, and $l, u$ are vectors of $\Re^n$ whose components are allowed
to be arbitrarily large in absolute value.

The inequality constraints are first internally reformulated as equalities by
the introduction of (non-negative) slack variables. This defines the set
$\calC$ of all (original and reformulated) equality constraints. The method
used to solve this reformulated problem is iterative and features two levels of
iteration. In the outer level, a composite function, the augmented Lagrangian
merit function,
\eqn{objectiveb}{
\phi( \bmx, \bmy, \mu ) = f(\bmx) + \sum_{i \in \calC}
 y_i c_i (\bmx) + \frac{1}{2 \mu} \sum_{i\in \calC} [c_i (\bmx)]^2,
}
is formulated, where $\mu$ is known as the penalty parameter,  $\bmy$ is a
vector of Lagrange multiplier estimates and $c_i$ now ranges over all
(original and reformulated) equality constraints.  Each outer iteration
requires the approximate minimization of this merit function
within the feasible box, for given values of $\mu$ and $\bmy$.

The required approximate minimization for fixed $\mu$ and $\bmy$ is
carried out using a series of inner iterations.  At each inner
iteration, a quadratic model of the merit function is
constructed.  An approximation to the minimizer of this model within a
trust-region is calculated.  The trust region is a ``box''
of specified radius, centered at the current best estimate
of the minimizer.  If there is an accurate agreement between the model
and the true objective function at the new approximation to the
minimizer, this approximation becomes the new best estimate.  Otherwise,
the radius of the trust region is reduced and a new approximate
minimizer sought.  The algorithm also allows the trust-region radius to
increase when necessary. The minimization of the model function is
carried out by using an iterative approach.

The approximate minimization of the model is performed in two stages.
In the first, a so-called generalized Cauchy point is determined
by approximately minimizing the model within the intersection of
the feasible box and the trust-region along a scaled steepest descent
direction. Having taken this step, the model is further reduced
by solving one or more quadratic minimization problems in which
any constraints activated at the Cauchy point remain so. The latter
computation is essentially equivalent to the solution of a sequence
of linear systems, and is performed using an iterative (preconditioned
conjugate gradient) method.

After an appropriate approximation to the minimizer of the merit
function is obtained, and if there are general constraints,
$\mu$ and $\bmy$ are adjusted to ensure
convergence of the outer iteration to the required solution of the
constrained minimization problem.

%%%%%%%%%%%%%%%%%%%%%% attributes %%%%%%%%%%%%%%%%%%%%%%

\galattributes
\galversions{\tt  \fullpackagename\_double},
\galuses {\tt LANCELOT}.
\galdate November 2007.
\galorigin N. I. M. Gould, Oxford University and Rutherford Appleton Laboratory,
England, D. Orban, Ecole Polytechnique, Montr\'{e}al, Canada, and
Ph. L. Toint, University of Namur - FUNDP, Belgium.
\gallanguage Fortran~95 + TR 15581 or Fortran~2003.

%%%%%%%%%%%%%%%%%%%%%% HOW TO USE %%%%%%%%%%%%%%%%%%%%%%

\galhowto

\subsection{Calling sequences}

Access to the package requires a {\tt USE} statement such as

\medskip\noindent{\em Single precision version}

\hskip0.5in {\tt USE \fullpackagename\_single}

\medskip\noindent{\em Double precision version}

\hskip0.5in {\tt USE  \fullpackagename\_double}

\medskip

\noindent
If it is required to use both modules at the same time,
the subroutine
{\tt \fullpackagename}
(Section~\ref{galarguments})
must be renamed on one of the {\tt USE} statements.

%%%%%%%%%%%%%%%%%%%%%% argument lists %%%%%%%%%%%%%%%%%%%%%%

\galarguments

The minimization subroutine {\tt LANCELOT\_simple} is called as follows:
\hskip0.5in
\def\baselinestretch{0.8} {\tt \begin{verbatim}
   CALL LANCELOT_simple( n, X, MY_FUN, fx, exit_code [,MY_GRAD] [,MY_HESS]    &
                        [,BL] [,BU] [,VNAMES] [,CNAMES]                       &
                        [,neq] [,nin] [,CX] [,Y] [,iters] [,maxit]            &
                        [,gradtol] [,feastol] [,print_level] )
\end{verbatim}}
\def\baselinestretch{1.0}
\noindent
where
\begin{description}
\ittf{n} is a scalar variable of type default \integer, that holds
the number of optimization variables, $n$ which must all be set on entry. It
will thereafter be unaltered.

\itt{X} is a rank-one array of dimension {\tt n} and type
default \realdp, that holds the current values of the
minimization variables, $\bmx$. On input, it must contain the values of the
variables corresponding to the minimization starting point.  On output, it
contains the best point found by the routine.

\itt{MY\_FUN} is a variable whose value is the name of a
user-supplied subroutine whose purpose is to compute objective function
and constraint values. See Section~\ref{pfe} for details.
The subroutine associated with the variable must be declared \external\
in the calling program.

\itt{fx} is a scalar variable of type default \realdp, that
holds  on output the value of the objective function $f$ at {\tt X}.

\itt{exit\_code} is a scalar variable of type default \integer, that holds
on output the final status for the minimization, a value 0 indicating
success.  Other values are described below (see Section~\ref{serrors}).

\itt{MY\_GRAD} is an \optional\ variable whose value is the name of a
user-supplied subroutine whose purpose is to compute the first derivatives
of the objective function and constraints. See Section~\ref{pfg} for details.
If {\tt MY\_GRAD} is present the subroutine associated with the variable must be
declared \external\ in the calling program. If the argument is not present,
first derivatives will be estimated by finite differences.

\itt{MY\_HESS} is an \optional\ variable whose value is the name of a
user-supplied subroutine whose purpose is to compute the second derivatives
of the objective function and constraints. See Section~\ref{pfh} for details.
If {\tt MY\_HESS} is present the subroutine associated with the variable must be
declared \external\ in the calling program. If the argument is not present,
or if {\tt MY\_GRAD} is not present,
second derivatives will be estimated by secant formulae.

\itt{BL} is an \optional\ rank-one array of dimension {\tt n} and type
 default \realdp, whose $i$-th entry may be set
to the value of the lower bound $l_i$ on the $i$-th variable.
If the $i$-th variable has no lower bound, {\tt BL($i$)} should be set to
a large negative number. It is not altered by the routine.

\itt{BU} is an \optional\ rank-one array of dimension {\tt n} and type
default \realdp, whose $i$-th entry may be set
to the value of the upper bound $u_i$ on the $i$-th variable.
If the $i$-th variable has no upper bound, {\tt BU($i$)} should be set to
a large positive number.  It is not altered by the routine.

\itt{CNAMES} is an \optional\  rank-one array of dimension {\tt neq + nin }
and type default \character\ and length 10, whose $i$-th entry contains (on
input) the ``name'' of the $i$-th equality constraint  for
{\tt i = 1, ..., neq} and of the $i$th inequality constraint for
{\tt i = neq+1, ..., neq+nin}.  It is not altered by the routine.

\itt{VNAMES} is an \optional\ rank-one array of dimension {\tt n} and type
default \character\ and length 10, whose $j$-th entry contains (on input) the
``name'' of the $j$-th variable.  It is not altered by the routine.

\itt{neq} is an \optional\ scalar variable of type default \integer, that holds
the number of equality constraints. If not present on input, it is assumed
that there are no inequality constraints {\tt neq = 0}). It is not altered by
the routine.

\itt{nin} is an \optional\ scalar variable of type default \integer, that holds
the number of inequality constraints. If not present on input, it is assumed
that there are no inequality constraints {\tt nin = 0}). It is not altered by
the routine.

\itt{CX} is an \optional\ rank-one array of dimension {\tt neq + nin} and type
default \realdp, whose $i$-th component holds on output the current
estimates of the values of the equality constraints ({\tt i = 1, ..., neq}),
and of the inequality constraints  ({\tt i = neq+1, ..., neq+nin}).

\itt{Y} is an \optional\ rank-one array of dimension {\tt neq+nin} and type
default \realdp, whose $i$-th component holds on output the current
estimates of the Lagrange multipliers, $\bmy$, for the equality constraints
({\tt i = 1, ..., neq}), and for the inequality constraints  ({\tt i = neq+1,
  ..., neq+nin}).

\itt{iters} is an \optional\ scalar variable of type default \integer, that gives
on output the number of iterations that have been performed since the start of
the  minimization.

\itt{maxit} is an \optional\ scalar variable of type default \integer, that
holds the maximum number of iterations which will be allowed in the solver.
The default is {\tt maxit = 1000}.

\itt{gradtol} is an \optional\ scalar variable of type default \realdp,
that is used to specify on input the maximum permitted (infinity)
norm of the projected gradient of the Lagrangian function
(see Section~\ref{galmethod}) at the estimate of the solution sought.
The default is {\tt gradtol =} $10^{-5}$.  It is not altered by the routine.

\itt{feastol} is an \optional\ scalar variable of type default \realdp,
that is used to specify on input the maximum permitted violation (measured in
infinity norm) of the constraints at the estimate of the solution sought.
The default is {\tt feastol =} $10^{-5}$.

\itt{print\_level} is an \optional\ scalar variable of type default \integer,
that is used to control on input the amount of informational output which is
required. No informational output will occur if {\tt print\_level} $\leq 0$. If
{\tt print\_level} $= 1$, a single line of output will be produced for each
iteration of the process, while additionally if {\tt print\_level} $= 2$
a summary of the inner iteration will be given.
If {\tt print\_level} $\geq 3$, this output will be
increased to provide significant detail of each iteration.
The default is {\tt print\_level = 1}.
\end{description}

\subsection{Function and derivative values\label{fdv}}

%%%%%%%%%%%%%%%%%%%%%% Problem function evaluation %%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Evaluating problem functions\label{pfe}}

{\tt LANCELOT\_simple} requires that the user provides a
subroutine, with prescribed argument lists, that accept input
values $(\bmx)$, and provide as output
$f(\bmx))$ or $c_i(\bmx)$ ($i \in \calC$).
This default routine name is {\tt FUN} and it must have the following argument
list:

\def\baselinestretch{0.8}
{\tt \begin{verbatim}
       SUBROUTINE FUN ( X, fx [,i] )
\end{verbatim} }\def\baselinestretch{1.0}
\noindent
where
\begin{description}
\itt{X} is a rank-one \intentin array argument of
dimension {\tt n} and type default \realdp,
that contains the values of $\bmx$ at which the
subroutine is required to evaluate the values
of the objective or constraint functions.

\itt{fx} is a rank-one \intentout scalar argument of
  type default \realdp, that contains the value of the relevant
  function evaluated at $\bmx$.

\itt{i} is an \optional\ scalar \intentin\ argument of type default \integer,
that, if present, specifies the index of the constraint function to be
evaluated  ({\tt i = 1, ..., neq+nin}).  The values of {\tt i}
between 1 and {\tt neq} correspond to equality constraints, those between
{\tt neq+1} and {\tt neq+nin} to inequality constraints. If {\tt i} is not
present, this indicates that the value of the objective function must be
evaluated.
\end{description}

\noindent
The name of the function evaluation routine may be modified by the user
by specifying {\tt MY\_FUN} to a value different from {\tt FUN} in the calling
sequence, but the argument list of the associated subroutine must be identical
to that described above. Specifying  {\tt MY\_FUN = FUN} is redundant in the
calling sequence if the name of the function evaluation routine is {\tt FUN}
(but this explicit identification is nevertheless recommended for clarity).

\subsubsection{Evaluating the first derivatives of problem functions\label{pfg}}

If the first derivatives of the problem functions are available, which is
indicated by the specification of the \optional\ argument {\tt MY\_GRAD}, they
must be available for the objective function and all constraints.
{\tt LANCELOT\_simple} then requires that the user provide a subroutine, with
a  prescribed argument list, that accepts input values $(\bmx)$, and returns as
output  $\nabla_x f(\bmx)$,  $\nabla_x c_e(\bmx)$ or $\nabla_x c_i(\bmx)$.
This routine is specified by setting the value of the \optional\ argument
{\tt MY\_GRAD}. If one uses {\tt MY\_GRAD = GRAD} in the call to {\tt
  LANCELOT\_simple}, the {\tt GRAD} routine must have the following argument
list:

\def\baselinestretch{0.8}
{\tt \begin{verbatim}
       SUBROUTINE GRAD ( X, G [,i] )
\end{verbatim} }
\def\baselinestretch{1.0}
\noindent
where
\begin{description}
\itt{X} is a rank-one \intentin\ array argument of
dimension {\tt n} and type default \realdp,
that contains the values of $\bmx$ at which the
subroutine is required to evaluate the gradient
of the objective or constraint function.

\itt{G} is a rank-one \intentout\ array argument of dimension {\tt n}  and
  type default \realdp, that contains the value of the relevant
  gradient evaluated at $\bmx$.

\itt{i} is an \optional\ scalar \intentin\ argument of type default \integer,
that, if present, specifies the index of the constraint function whose
gradient must be evaluated  ({\tt i = 1, ..., neq+nin}).  The values of {\tt i}
between 1 and {\tt neq} correspond to equality constraints, those between
{\tt neq+1} and {\tt neq+nin} to inequality constraints. If {\tt i} is not
present, this indicates that the gradient of the objective function must be
evaluated.
\end{description}

\subsubsection{Evaluating the second derivatives of problem
functions\label{pfh}}

If the second derivatives of the problem functions are available, which is
indicated by the specification of the \optional\ argument {\tt HESS}, they must
be available for the objective function and all constraints. Moreover, first
derivatives must also be available for all problem functions, and must be
specified as indicated in Section~\ref{pfg}.
{\tt LANCELOT\_simple} then requires that the user provide a subroutine, with
a prescribed argument list, that accepts input values $(\bmx)$, and returns as
output  $\nabla_{xx}f(\bmx)$,  $\nabla_{xx}c_e(\bmx)$ or
$\nabla_{xx}c_i(\bmx)$. This routine is specified by setting the value of the
\optional\ argument {\tt MY\_HESS}. If one uses {\tt MY\_HESS = HESS} in the
call to {\tt LANCELOT\_simple}, the {\tt HESS} routine must have the following
argument list:

\def\baselinestretch{0.8}
{\tt \begin{verbatim}
       SUBROUTINE HESS ( X, H [,i] )
\end{verbatim} }
\def\baselinestretch{1.0}
\noindent
where
\begin{description}
\itt{X} is a rank-one \intentin\ array argument of
dimension {\tt n} and type default \realdp,
that contains the value of $\bmx$ at which the
subroutine is required to evaluate the Hessian
of the objective or constraint function.

\itt{H} is a rank-one \intentout\ array argument of dimension {\tt n*(n+1)/2}
  and type default \realdp, that contains the value of the relevant
  Hessian evaluated at $\bmx$. Only the ``upper triangular'' part of the
  required Hessians should be specified columnwise. In other words, the
  component of the Hessian with respect to  variables $p$ and $j$, with
  $p \leq j$, must be  placed in {\tt H( j*(j-1)/2 + p )}.

\itt{i} is an \optional\ scalar \intentin\ argument of type default \integer,
that, if present, specifies the index of the constraint function whose
Hessian must be evaluated  ({\tt i = 1, ..., neq+nin}). The values of {\tt i}
between 1 and {\tt neq} correspond to equality constraints, those between
{\tt neq+1} and {\tt neq+nin} to inequality constraints.
If {\tt i} is not
present, this indicates that the Hessian of the objective function must be
evaluated.
\end{description}

\galerrors\label{serrors}

If {\tt exit\_code} is positive
on return from the solver, an error has been detected.
The user should correct the error and restart the minimization.
Possible values of {\tt exit\_code} and their consequences are:
\begin{description}
\itt{exit\_code $= 1.$} More than {\tt maxit} iterations have been
      performed. This is often a symptom of incorrectly programmed
      derivatives or of the preconditioner used being
      insufficiently effective. Recheck the derivatives.
      Otherwise, increase {\tt maxit} and re-enter \package\
      at the best point found so far.
\itt{exit\_code $= 2.$} The trust-region radius
      has become too small. This is
      often a symptom of incorrectly programmed derivatives
      or of requesting more accuracy in the projected gradient
      than is reasonable on the user's machine.
      If the projected gradient
      is small, the minimization
      has probably succeeded. Otherwise, recheck the derivatives.
\itt{exit\_code $= 3.$} The step taken during the current iteration is so
      small that
      no difference will be observed in the function values.
      This sometimes occurs when too much accuracy is required of
      the final gradient. If the projected gradient
      is small, the minimization has probably succeeded.
\itt{exit\_code $= 8.$} The problem does not appear to have a feasible
     solution. Check the constraints and try starting with a different
     initial value for $\bmx$.
\itt{exit\_code $= 15.$} The problem dimension
     {\tt n} is nonpositive. Ensure that {\tt n $>$ 0}.
\itt{exit\_code $= 19.$} One or both of the numbers of constraints
      {\tt neq} or {\tt nin} is negative. Ensure that both {\tt neq $\geq$ 0}
      and {\tt nin $\geq$ 0}.
\end{description}

\galinfo

The user is able to control the amount of intermediate printing
performed in the course of the minimization. Printing is under
the control of the parameter {\tt print\_level} and output is sent to
I/O unit number number 6. Possible values of {\tt print\_level} and the levels
of output produced are as follows.
\begin{description}
\itt{print\_level $\leq 0.$} No printing, except warning messages, will be
   performed.
\itt{print\_level $\geq 1.$} Details of the minimization function will be
   output. This includes the number of variables, and additional
   information on the internal data structures of the solver.

                 If the current iterate provides an acceptable
                 estimate of the minimizer of the augmented Lagrangian
                 function, the two-norm of the general constraints and
                 the current value of the penalty parameter are given.
\itt{print\_level $= 1.$} A simple one-line description of each iteration is
                 given. This includes the iteration number, the
                 number of derivative evaluations that have been
                 made, the number of conjugate-gradient iterations
                 that have been performed,
                 the current value of the augmented Lagrangian
                 function, the (two-) norm
                 of the projected gradient,
                 the ratio $\rho$ of actual to predicted decrease
                 in the augmented Lagrangian function value,
                 the current trust-region radius,
                 the norm of the step taken,
                 an indication of how the direct or iterative
                 method ended, the number of variables which lie
                 away from their bounds and the total time
                 spent on the minimization.
\itt{print\_level $= 2.$} In addition to the information output with
                 {\tt print\_level = 1},
                 a short description of the approximate solution
                 to the inner-iteration linear system is given.
                 Before a successful ({\tt exit\_code = 0}) exit, details of
                 the estimate of the minimizer and the
                 gradient of the augmented Lagrangian
                 function are given.
\itt{print\_level $= 3.$} A list of the current iteration number, the value
				 of the augmented Lagrangian function, the
                 number of derivative evaluations that have been
                 made, the (two-) norm
                 of the projected gradient,
                 the number of conjugate gradients
                 iterations that have been performed and the
                 current trust-region radius
                 are given, followed by the
                 current estimate of the minimizer.
                 The values of the reduction in the model of the
                 augmented Lagrangian function
                 and the actual reduction in this
                 function, together with their ratio, are also given.
                 Before a successful ({\tt exit\_code = 0}) exit, details of
                 the estimate of the minimizer and the
                 gradient of the augmented Lagrangian function are given.

                 If the current iterate also provides an acceptable
                 estimate of the minimizer of the augmented Lagrangian
                 function, values of the general constraints and
                 estimates of the Lagrange multipliers are also given.
\itt{print\_level $= 4.$} In addition to the information output with
                 {\tt print\_level= 3},
                 the gradient of the augmented Lagrangian function at
                 the current estimate of the minimizer is given.
                 Full details of the approximate solution
                 to the inner-iteration linear system are also given.
                 This level of output is intended as a debugging aid
                 for the expert only.
\itt{print\_level $= 5.$} In addition to the information output with
                 {\tt print\_level = 4},
                 the diagonal elements of the second derivative
                 approximation are given.
\itt{print\_level $\geq 6.$} In addition to the information output with
                  {\tt print\_level = 5},
                  the second derivative approximations
                  to each problem function are given.
\end{description}

%%%%%%%%%%%%%%%%%%%%%% GENERAL INFORMATION %%%%%%%%%%%%%%%%%%%%%%

\galgeneral

\galcommon None.
\galworkspace Provided automatically by the module.
\galroutines The user must provide an external {\tt MY\_FUN} subroutine
(see Section~\ref{pfe}), and optionally may provide
external {\tt MY\_GRAD} (see Section~\ref{pfg}) and
{\tt MY\_HESS} (see Section~\ref{pfh}) subroutines.
\galmodules
{\tt LANCELOT}.
\galio No input; output on device number 6.
    Output is provided under the control of {\tt print\_level}.
\galrestrictions
     {\tt n $>$ 0},
     {\tt neq $\geq$ 0},
     {\tt nin $\geq$ 0}.
\galportability ISO Fortran~95 + TR 15581 or Fortran~2003.
%The package is thread-safe.

%%%%%%%%%%%%%%%%%%%%%% METHOD %%%%%%%%%%%%%%%%%%%%%%

\galmethod
The basic method implemented within {\tt \packagename} and LANCELOT B is
described in detail by Conn, Gould and Toint (1991).  The method used to solve
the inner iteration subproblem is described by Conn, Gould and Toint
(1988b).  Also see Chapter~3 of the {\sf LANCELOT A} manual.

The Lagrangian function associated with the objective function
and the general constraints is the
composite function \disp{\ell( \bmx, \bmy ) = f(\bmx) + \sum_{i \in
\calC} y_i c_i (\bmx).}  The scalars $y_i$ are known as Lagrange
multiplier estimates.  At a solution $\bmx^{\star}$ to the constrained
minimization problem, there are Lagrange multipliers $\bmy^{\star}$ for
which the components of the gradient of the Lagrangian function
$\partial \ell(\bmx^{\star}, \bmy^{\star}) / \partial x_i= 0$ whenever
the corresponding variable $x_i^{\star}$ lies strictly between its lower
and upper bounds.

The augmented Lagrangian function is the composite function
\eqn{objectivec}{\phi( \bmx, \bmy, \mu ) = \ell( \bmx, \bmy) +
 \frac{1}{2 \mu} \sum_{i \in \calC} [c_i (\bmx)]^2,}
where $\mu$ is known as the penalty parameter.  An inner iteration is
used to find an approximate minimizer of (\ref{objectivec}) within the
feasible box for fixed values of the penalty parameter and Lagrange
multiplier estimates. The outer iteration of {\tt \packagename}
automatically adjusts the penalty parameter and Lagrange multiplier
estimates to ensure convergence of these approximate minimizers to a
solution of the constrained optimization problem.

In the inner iteration, a step from the current estimate of the solution
is determined using a trust-region approach.  That is, a quadratic model
of the augmented Lagrangian function is approximately minimized within
the intersection of the constraint ``box'' and another convex region,
the trust-region.  This minimization is carried out in two stages.
Firstly, the so-called generalized Cauchy point for the quadratic
subproblem is found.  (The purpose of this point is to ensure that the
algorithm converges and that the set of bounds which are satisfied as
equations at the solution is rapidly identified.)  Thereafter an
improvement to the quadratic model is sought using either a
direct-matrix or truncated conjugate-gradient algorithm. The
trust-region size is increased if the reduction obtained in the
objective function is reasonable when compared with the reduction
predicted by the model and reduced otherwise.

The strategy for treating bound constraints is based on the usual
projection and is described in detail in Conn, Gould and Toint (1988a).

\galreferences
\vspace*{1mm}

\noindent
The basic method is described in detail in
\vspace*{1mm}

\noindent
%\begin{center}
A. R. Conn, N. I. M. Gould and Ph. L. Toint (1992).
LANCELOT. A fortran package for large-scale nonlinear optimization
(release A). Soringer Verlag Series in Computational Mathematics 17,
Berlin,
%\end{center}

\noindent
and details of its computational performance may be found in

\noindent
%\begin{center}
A. R. Conn, N. I. M. Gould and Ph. L. Toint (1996).
Numerical experiments with the {\sf LANCELOT} package
(Release A) for large-scale nonlinear optimization
Mathematical Programming {\bf 73} 73-110.
%\end{center}

%\noindent
Convergence properties of the method are described in

\noindent
%\begin{center}
A. R. Conn, N. I. M. Gould and Ph. L. Toint (1991).
A Globally Convergent Augmented {L}agrangian Algorithm for
Optimization with General Constraints and Simple Bounds.
SIAM Journal on Numerical Analysis {\bf 28} 545-572,
%\end{center}

\noindent
and

\noindent
%\begin{center}
A. R. Conn, N. I. M. Gould and Ph. L. Toint (1988a).
Global convergence of a class of trust region algorithms
for optimization with simple bounds.
SIAM Journal on Numerical Analysis {\bf 25} 433-460,
%\end{center}

\noindent
while details of the inner iteration are provided by

\noindent
%\begin{center}
A. R. Conn, N. I. M. Gould and Ph. L. Toint (1988b).
Testing a class of methods for solving minimization
problems with simple bounds on the variables.
Mathematics of Computation {\bf 50} 399-430.
%\end{center}

%\noindent
Many of the newer issues are discussed by

\noindent
%\begin{center}
A. R. Conn, N. I. M. Gould and Ph. L. Toint (2000).
Trust Region Methods.
SIAM, Philadelphia.
%\end{center}

\noindent
An easy-to-read introduction to {\tt LANCELOT\_simple} is provided in

\noindent
N. I. M. Gould, D. Orban and Ph. L. Toint (2007).
LANCELOT\_simple, a simple interface to LANCELOT B.
Report 07/12, Department of Mathematics, University of Namur-FUNDP, Namur,
Belgium.

%%%%%%%%%%%%%%%%%%%%%% EXAMPLE %%%%%%%%%%%%%%%%%%%%%%

\galexample
We now consider the small example problem
\[
\min_{x_1,x_2 } f( x_1, x_2 ) = 100 ( x_2 - x_1^2 )^2 + ( 1 - x_1 )^2,
\]
subject to the constraints
\[
\begin{array}{rcl}
0  & \leq & x_1, \\
x_1 + 3x_2   - 3  &  = &  0,\\
x_1^2 + x_2^2 - 4 &  \leq & 0.
\end{array}
\]

\noindent
A simple Fortran program to use the interface on this problem is given as
follows.

\def\baselinestretch{0.8}{\tt \begin{verbatim}
      PROGRAM RUN_LANCELOT_simple

      USE LANCELOT_simple_double

      IMPLICIT NONE
      INTEGER, PARAMETER :: wp = KIND( 1.0D+0 ) ! set precision
      REAL ( KIND = wp ), PARAMETER :: infinity = 10.0_wp ** 20
      INTEGER :: n, neq, nin, iters, maxit, print_level, exit_code
      REAL ( KIND = wp ) :: gradtol, feastol, fx
      CHARACTER ( LEN = 10 ), ALLOCATABLE, DIMENSION(:) :: VNAMES, CNAMES
      REAL ( KIND = wp ),     ALLOCATABLE, DIMENSION(:) :: BL, BU, X, CX, Y
      EXTERNAL :: FUN, GRAD, HESS
!
! THE TEST PROBLEM DIMENSIONS (user defined)
!
       n   = 2  ! number of variables
       neq = 1  ! number of equality constraints, excluding fixed variables
       nin = 1  ! number of inequality (<= 0) constraints, excluding bounds
!
! allocate space for problem defining vectors
!
       ALLOCATE( X( n  ), BL( n ), BU( n ), CX( neq+nin ), Y( neq+nin ) )
       ALLOCATE( VNAMES( n  ), CNAMES( neq+nin ) )
!
! starting point
!
       X(1) = -1.2_wp                 ! starting point (componentwise)
       X(2) =  1.0_wp
!
! bounds on the variables
!
       BL(1) =  0.0_wp                ! lower bounds (componentwise)
       BL(2) = -infinity
       BU(1) =  infinity              ! upper bounds (componentwise)
       BU(2) =  3.0_wp
!
! names
!
       VNAMES(1) = 'x1'               ! variables
       VNAMES(2) = 'x2'
       CNAMES(1) = 'Equality'         ! equality constraints
       CNAMES(2) = 'Inequality'       ! inequality constraints
!
! algorithmic parameters
!
       maxit       = 100
       gradtol     = 0.00001_wp       ! identical to default
       feastol     = 0.00001_wp       ! identical to default
       print_level = 0                ! no output
!
! solve by calling LANCELOT_simple
!
       CALL LANCELOT_simple( n,  X, FUN, fx, exit_code,                    &
                            MY_GRAD = GRAD , MY_HESS = HESS,               &
                            BL = BL, BU = BU, VNAMES   =  VNAMES,          &
                            CNAMES =  CNAMES, NEQ = neq, NIN = nin,        &
                            CX = CX, Y = Y, ITERS  = iters, MAXIT = maxit, &
                            GRADTOL = gradtol, FEASTOL = feastol,          &
                            PRINT_LEVEL = print_level )
!
! act on return status
!
       IF ( exit_code == 0 ) THEN                  !  Successful return
          WRITE( 6, "( 1X, I0, ' iterations. Optimal objective value =',    &
      &    ES12.4, /, ' Optimal solution = ', ( 5ES12.4 ) )" ) iters, fx, X
       ELSE                                         !  Error returns
           WRITE( 6, "( ' LANCELOT_simple exit status = ', I0 ) " ) exit_code
       END IF
!
! clean up
!
       DEALLOCATE( X, BL, BU, CX, Y )
       DEALLOCATE( VNAMES, CNAMES )
!
       STOP
!
       END PROGRAM RUN_LANCELOT_simple
!
!.............................................................................
!
       SUBROUTINE FUN ( X, F, i )
       INTEGER, PARAMETER :: wp = KIND( 1.0D+0 ) ! set precision
       REAL( KIND = wp ), INTENT( IN )   :: X( : )
       REAL( KIND = wp ), INTENT( OUT )  :: F
       INTEGER, INTENT( IN ), OPTIONAL   :: i
       IF ( .NOT. PRESENT( i ) ) THEN
!         the objective function value (user defined)
!==============================================================================
          F = 100.0_wp*(X(2)-X(1)**2)**2 +(1.0_wp-X(1))**2                    !
!==============================================================================
       ELSE
          SELECT CASE ( i )
          CASE ( 1 )
!             the equality constraint value (user defined)
!==============================================================================
              F = X(1)+3.0_wp*X(2)-3.0_wp                                     !
!==============================================================================
          CASE ( 2 )
!             the inequality constraint value (user defined)
!==============================================================================
              F = X(1)**2+X(2)**2-4.0_wp                                      !
!==============================================================================
          END SELECT
       END IF
       RETURN
       END SUBROUTINE FUN
!
!.............................................................................
!
       SUBROUTINE GRAD( X, G, i )
       INTEGER, PARAMETER :: wp = KIND( 1.0D+0 ) ! set precision
       REAL( KIND = wp ), INTENT( IN )  :: X( : )
       REAL( KIND = wp ), INTENT( OUT ) :: G( : )
       INTEGER, INTENT( IN ), OPTIONAL  :: i
       IF ( .NOT. PRESENT( i ) ) THEN
!          the objective function's gradient components (user defined)
!==============================================================================
           G( 1 ) = -400.0_wp*(X(2)-X(1)**2)*X(1)-2.0_wp*(1.0_wp-X(1))        !
           G( 2 ) =  200.0_wp*(X(2)-X(1)**2)                                  !
!==============================================================================
       ELSE
          SELECT CASE ( i )
          CASE ( 1 )
!             the equality constraint's gradient components (user defined)
!==============================================================================
              G( 1 ) =  1.0_wp                                                !
              G( 2 ) =  3.0_wp                                                !
!==============================================================================
          CASE ( 2 )
!            the inequality constraint's gradient components (user defined)
!==============================================================================
              G( 1 ) =  2.0_wp*X(1)                                           !
              G( 2 ) =  2.0_wp*X(2)                                           !
!==============================================================================
          END SELECT
       END IF
       RETURN
       END SUBROUTINE GRAD
!
!.............................................................................
!
       SUBROUTINE HESS( X, H, i )
       INTEGER, PARAMETER :: wp = KIND( 1.0D+0 ) ! set precision
       REAL( KIND = wp ), INTENT( IN )  :: X( : )
       REAL( KIND = wp ), INTENT( OUT ) :: H( : )
       INTEGER, INTENT( IN ), OPTIONAL  :: i
       IF ( .NOT. PRESENT( i ) ) THEN
!        the entries of the upper triangle of the objective function's
!        Hessian  matrix,  stored by columns  (user defined)
!==============================================================================
          H( 1 ) = -400.0_wp*(X(2)-3.0_wp*X(1)**2)+2.0_wp                     !
          H( 2 ) = -400.0_wp*X(1)                                             !
          H( 3 ) =  200.0_wp                                                  !
!==============================================================================
       ELSE
          SELECT CASE ( i )
          CASE ( 1 )
!             the entries of the upper triangle of the equality
!             constraint's Hessian matrix, stored by columns (user defined)
!==============================================================================
              H( 1 ) = 0.0_wp                                                 !
              H( 2 ) = 0.0_wp                                                 !
              H( 3 ) = 0.0_wp                                                 !
!==============================================================================
          CASE ( 2 )
!            the entries of the upper triangle of the inequality
!            constraint's Hessian matrix, stored by columns (user defined)
!==============================================================================
              H( 1 ) = 2.0_wp                                                 !
              H( 2 ) = 0.0_wp                                                 !
              H( 3 ) = 2.0_wp                                                 !
!==============================================================================
          END SELECT
       END IF
       RETURN
       END SUBROUTINE HESS
!..............................................................................
\end{verbatim} }\def\baselinestretch{1.0}

\noindent
The use of the above calling program then produces the following output:

\def\baselinestretch{0.8}{\tt \begin{verbatim}
 8 iterations. Optimal objective value =  2.3314E-02
 Optimal solution =   8.4750E-01  7.1750E-01
\end{verbatim} }\def\baselinestretch{1.0}

\end{document}
