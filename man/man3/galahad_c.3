.TH "galahad.h" 3 "Mon May 1 2023" "C interfaces to GALAHAD" \" -*- nroff -*-
.ad l
.nh
.SH NAME
galahad.h
.SH SYNOPSIS
.br
.PP
.SH "Detailed Description"
.PP 

.SH "Introduction"
.PP
GALAHAD is foremost a modern fortran library of packages designed to solve continuous optimization problems, with a particular emphasis on those that involve a large number of unknowns\&. Since many application programs or applications are written in other languages, of late there has been a considerable effort to provide interfaces to GALAHAD\&. Thus there are Matlab interfaces, and here we provide details of those to C using the standardized ISO C support now provided within fortran\&.
.SS "Main authors"
N\&. I\&. M\&. Gould, STFC-Rutherford Appleton Laboratory, England, 
.br
 D\&. Orban, Polytechnique Montréal, Canada, 
.br
 D\&. P\&. Robinson, Leheigh University, USA, 
.br
 Ph\&. L\&. Toint, The University of Namur, Belgium, 
.br
 J\&. Fowkes, STFC-Rutherford Appleton Laboratory, England, and 
.br
 A\&. Montoison, Polytechnique Montréal, Canada\&.
.PP
GALAHAD provides packages as named for the following problems:
.PP
.PD 0
.IP "\(bu" 2
\fBfdc\fP - determine consistency and redundancy of linear systems   
.IP "\(bu" 2
\fBlpa\fP - linear programming using an active-set method   
.IP "\(bu" 2
\fBlpb\fP - linear programming using an interior-point method   
.IP "\(bu" 2
\fBwcp\fP - linear feasibility using an interior-point method   
.IP "\(bu" 2
\fBblls\fP - bound-constrained linear least-squares problems using a gradient-projection method   
.IP "\(bu" 2
bllsb - bound-constrained linear-least-squares using an interior-point method (in preparation) 
.IP "\(bu" 2
\fBslls\fP - simplex-constrained linear least-squares problems using a gradient-projection method   
.IP "\(bu" 2
\fBpresolve\fP - simplify quadratic programs prior to solution   
.IP "\(bu" 2
\fBbqp\fP - bound-constrained convex quadratic programming using a gradient-projection method   
.IP "\(bu" 2
\fBbqpb\fP - bound-constrained convex quadratic programming using an interior-point method   
.IP "\(bu" 2
\fBlsqp\fP - linear and separable quadratic programming using an interior-point method   
.IP "\(bu" 2
\fBcqp\fP - convex quadratic programming using an interior-point method   
.IP "\(bu" 2
\fBdqp\fP - convex quadratic programming using a dual active-set method   
.IP "\(bu" 2
\fBeqp\fP - equality-constrained quadratic programming using an iterative method   
.IP "\(bu" 2
\fBtrs\fP - the trust-region subproblem using matrix factorization   
.IP "\(bu" 2
\fBgltr\fP - the trust-region subproblem using matrix-vector products   
.IP "\(bu" 2
\fBrqs\fP - the regularized quadratic subproblem using matrix factorization   
.IP "\(bu" 2
\fBglrt\fP - the regularized quadratic subproblem using matrix-vector products   
.IP "\(bu" 2
\fBdps\fP - the trust-region and regularized quadratic subproblems in a diagonalising norm   
.IP "\(bu" 2
\fBlstr\fP - the least-squares trust-region subproblem using matrix-vector products   
.IP "\(bu" 2
\fBlsrt\fP - the regularized least-squares subproblem using matrix-vector products   
.IP "\(bu" 2
\fBl2rt\fP - the regularized linear l_2 norm subproblem using matrix-vector products   
.IP "\(bu" 2
\fBqpa\fP - general quadratic programming using an active-set method   
.IP "\(bu" 2
\fBqpb\fP - general quadratic programming using an interior-point method   
.IP "\(bu" 2
\fBtru\fP - unconstrained optimization using a trust-region method   
.IP "\(bu" 2
\fBarc\fP - unconstrained optimization using a regularization method   
.IP "\(bu" 2
\fBnls\fP - least-squares optimization using a regularization method   
.IP "\(bu" 2
\fBtrb\fP - bound-constrained optimization using a gradient-projection trust-region method   
.IP "\(bu" 2
\fBugo\fP - univariate global optimization   
.IP "\(bu" 2
\fBbgo\fP - multivariate global optimization in a box using a multi-start trust-region method   
.IP "\(bu" 2
\fBdgo\fP - multivariate global optimization in a box using a deterministic partition-and-bound method   
.IP "\(bu" 2
nlsb - bound-constrained least-squares optimization using a gradient-projection regularization method (in preparation) 
.IP "\(bu" 2
lancelot - general constrained optimization using an augmented Lagrangian method (interface in preparation) 
.IP "\(bu" 2
fisqp - general constrained optimization using an SQP method (in preparation)
.PP
In addition, there are packages for solving a variety of required sub tasks, and most specifically interface routines to external solvers for solving linear equations:
.PP
.PD 0
.IP "\(bu" 2
\fBuls\fP - unsymmetric linear systems   
.IP "\(bu" 2
\fBsls\fP - symmetric linear systems   
.IP "\(bu" 2
\fBsbls\fP - symmetric block linear systems   
.IP "\(bu" 2
\fBpsls\fP - preconditioners for symmetric linear systems  
.PP
C interfaces to all of these are underway, and each will be released once it is ready\&. If \fByou\fP have a particular need, please let us know, and we will raise its priority!
.PP
Interface header files are in $GALAHAD/include; that for a package named pack will be in the file galahad_pack\&.h\&. PDF documentation for pack will be in pack_c\&.pdf in the directory, and there is a man page entry in the file pack_c\&.3 in $GALAHAD/man/man3\&.
.SH "Further topics"
.PP
.SS "Unsymmetric matrix storage formats"
An unsymmetric m by n matrix A may be presented and stored in a variety of convenient input formats\&.
.PP
Both C-style (0 based) and fortran-style (1-based) indexing is allowed\&. Choose \fCcontrol\&.f_indexing\fP as \fCfalse\fP for C style and \fCtrue\fP for fortran style; the discussion below presumes C style, but add 1 to indices for the corresponding fortran version\&.
.PP
Wrappers will automatically convert between 0-based (C) and 1-based (fortran) array indexing, so may be used transparently from C\&. This conversion involves both time and memory overheads that may be avoided by supplying data that is already stored using 1-based indexing\&.
.SS "Dense storage format"
The matrix A is stored as a compact dense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array\&. In this case, component n * i + j of the storage array A_val will hold the value A_{ij} for 0 <= i <= m-1, 0 <= j <= n-1\&.
.SS "Dense storage format"
The matrix A is stored as a compact dense matrix by columns, that is, the values of the entries of each column in turn are stored in order within an appropriate real one-dimensional array\&. In this case, component m * j + i of the storage array A_val will hold the value A_{ij} for 0 <= i <= m-1, 0 <= j <= n-1\&.
.SS "Sparse co-ordinate storage format"
Only the nonzero entries of the matrices are stored\&. For the l-th entry, 0 <= l <= ne-1, of A, its row index i, column index j and value A_{ij}, 0 <= i <= m-1, 0 <= j <= n-1, are stored as the l-th components of the integer arrays A_row and A_col and real array A_val, respectively, while the number of nonzeros is recorded as A_ne = ne\&.
.SS "Sparse row-wise storage format"
Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1\&. For the i-th row of A the i-th component of the integer array A_ptr holds the position of the first entry in this row, while A_ptr(m) holds the total number of entries\&. The column indices j, 0 <= j <= n-1, and values A_{ij} of the nonzero entries in the i-th row are stored in components l = A_ptr(i), \&.\&.\&., A_ptr(i+1)-1, 0 <= i <= m-1, of the integer array A_col, and real array A_val, respectively\&. For sparse matrices, this scheme almost always requires less storage than its predecessor\&.
.SS "Sparse column-wise storage format"
Once again only the nonzero entries are stored, but this time they are ordered so that those in column j appear directly before those in column j+1\&. For the j-th column of A the j-th component of the integer array A_ptr holds the position of the first entry in this column, while A_ptr(n) holds the total number of entries\&. The row indices i, 0 <= i <= m-1, and values A_{ij} of the nonzero entries in the j-th columnsare stored in components l = A_ptr(j), \&.\&.\&., A_ptr(j+1)-1, 0 <= j <= n-1, of the integer array A_row, and real array A_val, respectively\&. As before, for sparse matrices, this scheme almost always requires less storage than the co-ordinate format\&.
.SS "Symmetric matrix storage formats"
Likewise, a symmetric n by n matrix H may be presented and stored in a variety of formats\&. But crucially symmetry is exploited by only storing values from the lower triangular part (i\&.e, those entries that lie on or below the leading diagonal)\&.
.SS "Dense storage format"
The matrix H is stored as a compact dense matrix by rows, that is, the values of the entries of each row in turn are stored in order within an appropriate real one-dimensional array\&. Since H is symmetric, only the lower triangular part (that is the part H_{ij} for 0 <= j <= i <= n-1) need be held\&. In this case the lower triangle should be stored by rows, that is component i * i / 2 + j of the storage array H_val will hold the value H_{ij} (and, by symmetry, h_{ji}) for 0 <= j <= i <= n-1\&.
.SS "Sparse co-ordinate storage format"
Only the nonzero entries of the matrices are stored\&. For the l-th entry, 0 <= l <= ne-1, of H, its row index i, column index j and value h_{ij}, 0 <= j <= i <= n-1, are stored as the l-th components of the integer arrays H_row and H_col and real array H_val, respectively, while the number of nonzeros is recorded as H_ne = ne\&. Note that only the entries in the lower triangle should be stored\&.
.SS "Sparse row-wise storage format"
Again only the nonzero entries are stored, but this time they are ordered so that those in row i appear directly before those in row i+1\&. For the i-th row of H the i-th component of the integer array H_ptr holds the position of the first entry in this row, while H_ptr(n) holds the total number of entries\&. The column indices j, 0 <= j <= i, and values H_{ij} of the entries in the i-th row are stored in components l = H_ptr(i), \&.\&.\&., H_ptr(i+1)-1 of the integer array H_col, and real array H_val, respectively\&. Note that as before only the entries in the lower triangle should be stored\&. For sparse matrices, this scheme almost always requires less storage than its predecessor\&.
.SS "Diagonal storage format"
If H is diagonal (i\&.e\&., h_{ij} = 0 for all 0 <= i /= j <= n-1) only the diagonals entries h_{ii}, 0 <= i <= n-1 need be stored, and the first n components of the array H_val may be used for the purpose\&.
.SS "Multiples of the identity storage format"
If H is a multiple of the identity matrix, (i\&.e\&., H = alpha I where I is the n by n identity matrix and alpha is a scalar), it suffices to store alpha as the first component of H_val\&.
.SS "The identity matrix format"
If H is the identity matrix, no values need be stored\&.
.SS "The zero matrix format"
The same is true if H is the zero matrix\&. 
.SH "Author"
.PP 
Generated automatically by Doxygen for C interfaces to GALAHAD from the source code\&.
